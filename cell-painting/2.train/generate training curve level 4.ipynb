{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06345df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.insert(0, \"../../scripts\")\n",
    "from utils import load_data\n",
    "\n",
    "\n",
    "from pycytominer.cyto_utils import infer_cp_features\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow import keras\n",
    "\n",
    "from vae import VAE\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import seaborn\n",
    "import random as python_random\n",
    "import tensorflow as tf\n",
    "# import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c62b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c4f536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_splits = [\"train\", \"test\", \"valid\", \"complete\"]\n",
    "data_dict = load_data(data_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16715d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "meta_features = infer_cp_features(data_dict[\"train\"], metadata=True)\n",
    "cp_features = infer_cp_features(data_dict[\"train\"])\n",
    "\n",
    "train_features_df = data_dict[\"train\"].reindex(cp_features, axis=\"columns\")\n",
    "train_meta_df = data_dict[\"train\"].reindex(meta_features, axis=\"columns\")\n",
    "\n",
    "test_features_df = data_dict[\"test\"].reindex(cp_features, axis=\"columns\")\n",
    "test_meta_df = data_dict[\"test\"].reindex(meta_features, axis=\"columns\")\n",
    "\n",
    "valid_features_df = data_dict[\"valid\"].reindex(cp_features, axis=\"columns\")\n",
    "valid_meta_df = data_dict[\"valid\"].reindex(meta_features, axis=\"columns\")\n",
    "\n",
    "complete_features_df = data_dict[\"complete\"].reindex(cp_features, axis=\"columns\")\n",
    "complete_meta_df = data_dict[\"complete\"].reindex(meta_features, axis=\"columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc7c541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40242, 685)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cells_AreaShape_Compactness</th>\n",
       "      <th>Cells_AreaShape_Eccentricity</th>\n",
       "      <th>Cells_AreaShape_Extent</th>\n",
       "      <th>Cells_AreaShape_FormFactor</th>\n",
       "      <th>Cells_AreaShape_MedianRadius</th>\n",
       "      <th>Cells_AreaShape_Orientation</th>\n",
       "      <th>Cells_AreaShape_Solidity</th>\n",
       "      <th>Cells_AreaShape_Zernike_0_0</th>\n",
       "      <th>Cells_AreaShape_Zernike_1_1</th>\n",
       "      <th>Cells_AreaShape_Zernike_2_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Nuclei_Texture_SumEntropy_DNA_5_0</th>\n",
       "      <th>Nuclei_Texture_SumEntropy_Mito_5_0</th>\n",
       "      <th>Nuclei_Texture_SumEntropy_RNA_20_0</th>\n",
       "      <th>Nuclei_Texture_SumEntropy_RNA_5_0</th>\n",
       "      <th>Nuclei_Texture_SumVariance_DNA_20_0</th>\n",
       "      <th>Nuclei_Texture_SumVariance_RNA_20_0</th>\n",
       "      <th>Nuclei_Texture_Variance_DNA_20_0</th>\n",
       "      <th>Nuclei_Texture_Variance_ER_20_0</th>\n",
       "      <th>Nuclei_Texture_Variance_RNA_10_0</th>\n",
       "      <th>Nuclei_Texture_Variance_RNA_20_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19790</td>\n",
       "      <td>0.69605</td>\n",
       "      <td>0.40400</td>\n",
       "      <td>0.30834</td>\n",
       "      <td>0.19317</td>\n",
       "      <td>0.71895</td>\n",
       "      <td>0.38837</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.62494</td>\n",
       "      <td>0.87362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61045</td>\n",
       "      <td>0.41907</td>\n",
       "      <td>0.64945</td>\n",
       "      <td>0.65199</td>\n",
       "      <td>0.22660</td>\n",
       "      <td>0.32108</td>\n",
       "      <td>0.29776</td>\n",
       "      <td>0.26173</td>\n",
       "      <td>0.34524</td>\n",
       "      <td>0.32151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18605</td>\n",
       "      <td>0.68873</td>\n",
       "      <td>0.41051</td>\n",
       "      <td>0.31982</td>\n",
       "      <td>0.19885</td>\n",
       "      <td>0.72510</td>\n",
       "      <td>0.39552</td>\n",
       "      <td>0.38362</td>\n",
       "      <td>0.65094</td>\n",
       "      <td>0.89679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61393</td>\n",
       "      <td>0.38269</td>\n",
       "      <td>0.63814</td>\n",
       "      <td>0.68204</td>\n",
       "      <td>0.23700</td>\n",
       "      <td>0.32808</td>\n",
       "      <td>0.27981</td>\n",
       "      <td>0.26893</td>\n",
       "      <td>0.34938</td>\n",
       "      <td>0.33179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.19083</td>\n",
       "      <td>0.66276</td>\n",
       "      <td>0.38585</td>\n",
       "      <td>0.31437</td>\n",
       "      <td>0.20415</td>\n",
       "      <td>0.71380</td>\n",
       "      <td>0.38701</td>\n",
       "      <td>0.36699</td>\n",
       "      <td>0.60932</td>\n",
       "      <td>0.88492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60850</td>\n",
       "      <td>0.41850</td>\n",
       "      <td>0.63529</td>\n",
       "      <td>0.65208</td>\n",
       "      <td>0.22852</td>\n",
       "      <td>0.32710</td>\n",
       "      <td>0.29371</td>\n",
       "      <td>0.27159</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>0.31965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 685 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cells_AreaShape_Compactness  Cells_AreaShape_Eccentricity  \\\n",
       "0                      0.19790                       0.69605   \n",
       "1                      0.18605                       0.68873   \n",
       "2                      0.19083                       0.66276   \n",
       "\n",
       "   Cells_AreaShape_Extent  Cells_AreaShape_FormFactor  \\\n",
       "0                 0.40400                     0.30834   \n",
       "1                 0.41051                     0.31982   \n",
       "2                 0.38585                     0.31437   \n",
       "\n",
       "   Cells_AreaShape_MedianRadius  Cells_AreaShape_Orientation  \\\n",
       "0                       0.19317                      0.71895   \n",
       "1                       0.19885                      0.72510   \n",
       "2                       0.20415                      0.71380   \n",
       "\n",
       "   Cells_AreaShape_Solidity  Cells_AreaShape_Zernike_0_0  \\\n",
       "0                   0.38837                      0.38668   \n",
       "1                   0.39552                      0.38362   \n",
       "2                   0.38701                      0.36699   \n",
       "\n",
       "   Cells_AreaShape_Zernike_1_1  Cells_AreaShape_Zernike_2_0  ...  \\\n",
       "0                      0.62494                      0.87362  ...   \n",
       "1                      0.65094                      0.89679  ...   \n",
       "2                      0.60932                      0.88492  ...   \n",
       "\n",
       "   Nuclei_Texture_SumEntropy_DNA_5_0  Nuclei_Texture_SumEntropy_Mito_5_0  \\\n",
       "0                            0.61045                             0.41907   \n",
       "1                            0.61393                             0.38269   \n",
       "2                            0.60850                             0.41850   \n",
       "\n",
       "   Nuclei_Texture_SumEntropy_RNA_20_0  Nuclei_Texture_SumEntropy_RNA_5_0  \\\n",
       "0                             0.64945                            0.65199   \n",
       "1                             0.63814                            0.68204   \n",
       "2                             0.63529                            0.65208   \n",
       "\n",
       "   Nuclei_Texture_SumVariance_DNA_20_0  Nuclei_Texture_SumVariance_RNA_20_0  \\\n",
       "0                              0.22660                              0.32108   \n",
       "1                              0.23700                              0.32808   \n",
       "2                              0.22852                              0.32710   \n",
       "\n",
       "   Nuclei_Texture_Variance_DNA_20_0  Nuclei_Texture_Variance_ER_20_0  \\\n",
       "0                           0.29776                          0.26173   \n",
       "1                           0.27981                          0.26893   \n",
       "2                           0.29371                          0.27159   \n",
       "\n",
       "   Nuclei_Texture_Variance_RNA_10_0  Nuclei_Texture_Variance_RNA_20_0  \n",
       "0                           0.34524                           0.32151  \n",
       "1                           0.34938                           0.33179  \n",
       "2                           0.33871                           0.31965  \n",
       "\n",
       "[3 rows x 685 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_features_df.shape)\n",
    "train_features_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef12cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_each_column(df):\n",
    "    columns = df.columns\n",
    "    df_copy = df.copy()\n",
    "    for column in columns:\n",
    "        df_copy[column] = df_copy[column].sample(frac=1).reset_index(drop=True)\n",
    "    return (df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dcb43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_df = shuffle_each_column(train_features_df)\n",
    "valid_features_df = shuffle_each_column(valid_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ab060de",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_architecture=[250]\n",
    "decoder_architecture=[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041e618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 02:10:07.379031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-14 02:10:07.379082: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-14 02:10:07.379127: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-3-81): /proc/driver/nvidia/version does not exist\n",
      "2022-01-14 02:10:07.379474: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "cp_vae = VAE(\n",
    "    input_dim=train_features_df.shape[1],\n",
    "    latent_dim=90,\n",
    "    batch_size=32,\n",
    "    encoder_batch_norm=True,\n",
    "    epochs=50,\n",
    "    learning_rate=0.0001,\n",
    "    encoder_architecture=encoder_architecture,\n",
    "    decoder_architecture=decoder_architecture,\n",
    "    beta=0.06,\n",
    "    verbose=True,\n",
    ")\n",
    "cp_vae.compile_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d01b91a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 02:10:09.096960: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1258/1258 [==============================] - 11s 7ms/step - loss: 54.8923 - recon: 53.5778 - kl: 1.3144 - mmd: 0.0000e+00 - val_loss: 12.1777 - val_recon: 10.9528 - val_kl: 1.2248 - val_mmd: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 8.3507 - recon: 7.3164 - kl: 1.0343 - mmd: 0.0000e+00 - val_loss: 6.6617 - val_recon: 5.6243 - val_kl: 1.0374 - val_mmd: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 5.1262 - recon: 4.3243 - kl: 0.8020 - mmd: 0.0000e+00 - val_loss: 4.5070 - val_recon: 3.7012 - val_kl: 0.8058 - val_mmd: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 3.4647 - recon: 2.8889 - kl: 0.5757 - mmd: 0.0000e+00 - val_loss: 2.8894 - val_recon: 2.3861 - val_kl: 0.5032 - val_mmd: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 2.4404 - recon: 2.0658 - kl: 0.3747 - mmd: 0.0000e+00 - val_loss: 2.1286 - val_recon: 1.7926 - val_kl: 0.3360 - val_mmd: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.8234 - recon: 1.6093 - kl: 0.2141 - mmd: 0.0000e+00 - val_loss: 1.5838 - val_recon: 1.4069 - val_kl: 0.1769 - val_mmd: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.4601 - recon: 1.3505 - kl: 0.1095 - mmd: 0.0000e+00 - val_loss: 1.3171 - val_recon: 1.2221 - val_kl: 0.0950 - val_mmd: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.2697 - recon: 1.2140 - kl: 0.0557 - mmd: 0.0000e+00 - val_loss: 1.1718 - val_recon: 1.1247 - val_kl: 0.0471 - val_mmd: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.1722 - recon: 1.1393 - kl: 0.0328 - mmd: 0.0000e+00 - val_loss: 1.1034 - val_recon: 1.0674 - val_kl: 0.0360 - val_mmd: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.1206 - recon: 1.0988 - kl: 0.0219 - mmd: 0.0000e+00 - val_loss: 1.0616 - val_recon: 1.0388 - val_kl: 0.0228 - val_mmd: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0909 - recon: 1.0767 - kl: 0.0142 - mmd: 0.0000e+00 - val_loss: 1.0364 - val_recon: 1.0210 - val_kl: 0.0154 - val_mmd: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0726 - recon: 1.0646 - kl: 0.0080 - mmd: 0.0000e+00 - val_loss: 1.0391 - val_recon: 1.0118 - val_kl: 0.0273 - val_mmd: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0609 - recon: 1.0572 - kl: 0.0037 - mmd: 0.0000e+00 - val_loss: 1.0328 - val_recon: 1.0065 - val_kl: 0.0263 - val_mmd: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0543 - recon: 1.0529 - kl: 0.0014 - mmd: 0.0000e+00 - val_loss: 1.1156 - val_recon: 1.0053 - val_kl: 0.1103 - val_mmd: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0506 - recon: 1.0500 - kl: 5.9027e-04 - mmd: 0.0000e+00 - val_loss: 1.1101 - val_recon: 1.0016 - val_kl: 0.1085 - val_mmd: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0481 - recon: 1.0478 - kl: 3.3954e-04 - mmd: 0.0000e+00 - val_loss: 1.1313 - val_recon: 1.0004 - val_kl: 0.1309 - val_mmd: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0467 - recon: 1.0464 - kl: 2.6198e-04 - mmd: 0.0000e+00 - val_loss: 1.1965 - val_recon: 0.9995 - val_kl: 0.1970 - val_mmd: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0456 - recon: 1.0453 - kl: 2.2623e-04 - mmd: 0.0000e+00 - val_loss: 1.0796 - val_recon: 0.9974 - val_kl: 0.0822 - val_mmd: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0446 - recon: 1.0444 - kl: 2.0063e-04 - mmd: 0.0000e+00 - val_loss: 1.1478 - val_recon: 0.9967 - val_kl: 0.1510 - val_mmd: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0441 - recon: 1.0440 - kl: 1.7971e-04 - mmd: 0.0000e+00 - val_loss: 1.1393 - val_recon: 0.9955 - val_kl: 0.1439 - val_mmd: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0434 - recon: 1.0433 - kl: 1.5529e-04 - mmd: 0.0000e+00 - val_loss: 1.1213 - val_recon: 0.9957 - val_kl: 0.1256 - val_mmd: 0.0000e+00\n",
      "Epoch 22/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0430 - recon: 1.0429 - kl: 1.3699e-04 - mmd: 0.0000e+00 - val_loss: 1.1213 - val_recon: 0.9947 - val_kl: 0.1265 - val_mmd: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0427 - recon: 1.0425 - kl: 1.2111e-04 - mmd: 0.0000e+00 - val_loss: 1.1535 - val_recon: 0.9931 - val_kl: 0.1603 - val_mmd: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0424 - recon: 1.0423 - kl: 1.0815e-04 - mmd: 0.0000e+00 - val_loss: 1.1833 - val_recon: 0.9950 - val_kl: 0.1883 - val_mmd: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0420 - recon: 1.0419 - kl: 9.6894e-05 - mmd: 0.0000e+00 - val_loss: 1.0432 - val_recon: 0.9940 - val_kl: 0.0493 - val_mmd: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0418 - recon: 1.0417 - kl: 8.3672e-05 - mmd: 0.0000e+00 - val_loss: 1.0290 - val_recon: 0.9926 - val_kl: 0.0364 - val_mmd: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0415 - recon: 1.0414 - kl: 7.5653e-05 - mmd: 0.0000e+00 - val_loss: 1.0130 - val_recon: 0.9932 - val_kl: 0.0198 - val_mmd: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0412 - recon: 1.0411 - kl: 6.5332e-05 - mmd: 0.0000e+00 - val_loss: 1.0084 - val_recon: 0.9937 - val_kl: 0.0147 - val_mmd: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0410 - recon: 1.0409 - kl: 5.5768e-05 - mmd: 0.0000e+00 - val_loss: 0.9985 - val_recon: 0.9922 - val_kl: 0.0063 - val_mmd: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0408 - recon: 1.0407 - kl: 4.7342e-05 - mmd: 0.0000e+00 - val_loss: 0.9983 - val_recon: 0.9928 - val_kl: 0.0055 - val_mmd: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0406 - recon: 1.0406 - kl: 4.0427e-05 - mmd: 0.0000e+00 - val_loss: 0.9949 - val_recon: 0.9916 - val_kl: 0.0033 - val_mmd: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0404 - recon: 1.0403 - kl: 3.5600e-05 - mmd: 0.0000e+00 - val_loss: 0.9944 - val_recon: 0.9929 - val_kl: 0.0015 - val_mmd: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0403 - recon: 1.0402 - kl: 3.1001e-05 - mmd: 0.0000e+00 - val_loss: 0.9949 - val_recon: 0.9923 - val_kl: 0.0026 - val_mmd: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0401 - recon: 1.0401 - kl: 2.7761e-05 - mmd: 0.0000e+00 - val_loss: 0.9923 - val_recon: 0.9913 - val_kl: 9.4185e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0399 - recon: 1.0399 - kl: 2.5768e-05 - mmd: 0.0000e+00 - val_loss: 0.9922 - val_recon: 0.9914 - val_kl: 7.7659e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0398 - recon: 1.0398 - kl: 2.3684e-05 - mmd: 0.0000e+00 - val_loss: 0.9926 - val_recon: 0.9917 - val_kl: 8.4635e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0396 - recon: 1.0396 - kl: 2.2109e-05 - mmd: 0.0000e+00 - val_loss: 0.9917 - val_recon: 0.9912 - val_kl: 4.6147e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0396 - recon: 1.0396 - kl: 2.0601e-05 - mmd: 0.0000e+00 - val_loss: 0.9914 - val_recon: 0.9908 - val_kl: 6.5161e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0395 - recon: 1.0394 - kl: 1.8671e-05 - mmd: 0.0000e+00 - val_loss: 0.9914 - val_recon: 0.9910 - val_kl: 3.6098e-04 - val_mmd: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0393 - recon: 1.0392 - kl: 1.7287e-05 - mmd: 0.0000e+00 - val_loss: 0.9917 - val_recon: 0.9914 - val_kl: 2.8662e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0392 - recon: 1.0391 - kl: 1.6137e-05 - mmd: 0.0000e+00 - val_loss: 0.9902 - val_recon: 0.9900 - val_kl: 2.1700e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0391 - recon: 1.0390 - kl: 1.5350e-05 - mmd: 0.0000e+00 - val_loss: 0.9904 - val_recon: 0.9902 - val_kl: 1.5502e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0390 - recon: 1.0390 - kl: 1.4347e-05 - mmd: 0.0000e+00 - val_loss: 0.9917 - val_recon: 0.9916 - val_kl: 1.2268e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0389 - recon: 1.0389 - kl: 1.3935e-05 - mmd: 0.0000e+00 - val_loss: 0.9909 - val_recon: 0.9907 - val_kl: 1.2268e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0388 - recon: 1.0388 - kl: 1.2792e-05 - mmd: 0.0000e+00 - val_loss: 0.9912 - val_recon: 0.9911 - val_kl: 9.6594e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0387 - recon: 1.0387 - kl: 1.2311e-05 - mmd: 0.0000e+00 - val_loss: 0.9895 - val_recon: 0.9893 - val_kl: 1.0492e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0386 - recon: 1.0386 - kl: 1.1931e-05 - mmd: 0.0000e+00 - val_loss: 0.9896 - val_recon: 0.9895 - val_kl: 1.0201e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0385 - recon: 1.0385 - kl: 1.1655e-05 - mmd: 0.0000e+00 - val_loss: 0.9897 - val_recon: 0.9896 - val_kl: 9.3981e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0386 - recon: 1.0385 - kl: 1.0614e-05 - mmd: 0.0000e+00 - val_loss: 0.9901 - val_recon: 0.9900 - val_kl: 1.2518e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0383 - recon: 1.0383 - kl: 9.7430e-06 - mmd: 0.0000e+00 - val_loss: 0.9901 - val_recon: 0.9901 - val_kl: 8.4975e-05 - val_mmd: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "cp_vae.train(x_train=train_features_df, x_test=valid_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd5bacb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fa70ae53890>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_vae.vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0b78c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recon</th>\n",
       "      <th>kl</th>\n",
       "      <th>mmd</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recon</th>\n",
       "      <th>val_kl</th>\n",
       "      <th>val_mmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.892296</td>\n",
       "      <td>53.577824</td>\n",
       "      <td>1.314364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.177666</td>\n",
       "      <td>10.952815</td>\n",
       "      <td>1.224849</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.350660</td>\n",
       "      <td>7.316357</td>\n",
       "      <td>1.034306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.661676</td>\n",
       "      <td>5.624257</td>\n",
       "      <td>1.037420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.126224</td>\n",
       "      <td>4.324258</td>\n",
       "      <td>0.801971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.507024</td>\n",
       "      <td>3.701198</td>\n",
       "      <td>0.805828</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.464654</td>\n",
       "      <td>2.888922</td>\n",
       "      <td>0.575735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.889389</td>\n",
       "      <td>2.386144</td>\n",
       "      <td>0.503246</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.440433</td>\n",
       "      <td>2.065762</td>\n",
       "      <td>0.374671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.128606</td>\n",
       "      <td>1.792644</td>\n",
       "      <td>0.335962</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.823447</td>\n",
       "      <td>1.609350</td>\n",
       "      <td>0.214099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583832</td>\n",
       "      <td>1.406919</td>\n",
       "      <td>0.176913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.460065</td>\n",
       "      <td>1.350541</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.317115</td>\n",
       "      <td>1.222072</td>\n",
       "      <td>0.095043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.269654</td>\n",
       "      <td>1.213995</td>\n",
       "      <td>0.055659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.171761</td>\n",
       "      <td>1.124651</td>\n",
       "      <td>0.047110</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.172160</td>\n",
       "      <td>1.139324</td>\n",
       "      <td>0.032835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.103393</td>\n",
       "      <td>1.067432</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.120640</td>\n",
       "      <td>1.098759</td>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.061594</td>\n",
       "      <td>1.038763</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.090864</td>\n",
       "      <td>1.076697</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.036398</td>\n",
       "      <td>1.020974</td>\n",
       "      <td>0.015424</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.072605</td>\n",
       "      <td>1.064643</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039127</td>\n",
       "      <td>1.011789</td>\n",
       "      <td>0.027338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.060933</td>\n",
       "      <td>1.057243</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.032781</td>\n",
       "      <td>1.006457</td>\n",
       "      <td>0.026324</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.054316</td>\n",
       "      <td>1.052867</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.115550</td>\n",
       "      <td>1.005274</td>\n",
       "      <td>0.110276</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.050584</td>\n",
       "      <td>1.049993</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.110064</td>\n",
       "      <td>1.001574</td>\n",
       "      <td>0.108491</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.048113</td>\n",
       "      <td>1.047774</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.131331</td>\n",
       "      <td>1.000406</td>\n",
       "      <td>0.130925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.046701</td>\n",
       "      <td>1.046438</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.196488</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>0.196956</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.045563</td>\n",
       "      <td>1.045336</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.079571</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>0.082217</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.044625</td>\n",
       "      <td>1.044424</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.147773</td>\n",
       "      <td>0.996725</td>\n",
       "      <td>0.151047</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.044149</td>\n",
       "      <td>1.043969</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.139311</td>\n",
       "      <td>0.995452</td>\n",
       "      <td>0.143859</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.043407</td>\n",
       "      <td>1.043251</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.121268</td>\n",
       "      <td>0.995662</td>\n",
       "      <td>0.125607</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.043007</td>\n",
       "      <td>1.042871</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.121299</td>\n",
       "      <td>0.994750</td>\n",
       "      <td>0.126550</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.042669</td>\n",
       "      <td>1.042547</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.153478</td>\n",
       "      <td>0.993144</td>\n",
       "      <td>0.160335</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.042414</td>\n",
       "      <td>1.042306</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.183293</td>\n",
       "      <td>0.995011</td>\n",
       "      <td>0.188282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.042008</td>\n",
       "      <td>1.041911</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.043247</td>\n",
       "      <td>0.993954</td>\n",
       "      <td>0.049292</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.041754</td>\n",
       "      <td>1.041670</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.028952</td>\n",
       "      <td>0.992582</td>\n",
       "      <td>0.036369</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.041455</td>\n",
       "      <td>1.041380</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.013046</td>\n",
       "      <td>0.993216</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.041185</td>\n",
       "      <td>1.041120</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.008431</td>\n",
       "      <td>0.993690</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.040969</td>\n",
       "      <td>1.040913</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>0.992193</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.040797</td>\n",
       "      <td>1.040749</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998303</td>\n",
       "      <td>0.992786</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.040649</td>\n",
       "      <td>1.040609</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994916</td>\n",
       "      <td>0.991644</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.040385</td>\n",
       "      <td>1.040349</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994397</td>\n",
       "      <td>0.992904</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.040267</td>\n",
       "      <td>1.040236</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994891</td>\n",
       "      <td>0.992291</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.040143</td>\n",
       "      <td>1.040116</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992281</td>\n",
       "      <td>0.991340</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.039915</td>\n",
       "      <td>1.039889</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992211</td>\n",
       "      <td>0.991435</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.039779</td>\n",
       "      <td>1.039755</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992571</td>\n",
       "      <td>0.991725</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.039642</td>\n",
       "      <td>1.039619</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991664</td>\n",
       "      <td>0.991203</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.039596</td>\n",
       "      <td>1.039576</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991449</td>\n",
       "      <td>0.990797</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.039450</td>\n",
       "      <td>1.039431</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991404</td>\n",
       "      <td>0.991043</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.039266</td>\n",
       "      <td>1.039248</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991717</td>\n",
       "      <td>0.991431</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.039165</td>\n",
       "      <td>1.039149</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990233</td>\n",
       "      <td>0.990016</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.039062</td>\n",
       "      <td>1.039048</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990392</td>\n",
       "      <td>0.990237</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.039017</td>\n",
       "      <td>1.039001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991719</td>\n",
       "      <td>0.991596</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.038949</td>\n",
       "      <td>1.038936</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990852</td>\n",
       "      <td>0.990730</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.038826</td>\n",
       "      <td>1.038813</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991205</td>\n",
       "      <td>0.991109</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.038746</td>\n",
       "      <td>1.038733</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989452</td>\n",
       "      <td>0.989347</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.038569</td>\n",
       "      <td>1.038557</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989588</td>\n",
       "      <td>0.989486</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.038548</td>\n",
       "      <td>1.038537</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989657</td>\n",
       "      <td>0.989563</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.038553</td>\n",
       "      <td>1.038542</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990145</td>\n",
       "      <td>0.990020</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.038270</td>\n",
       "      <td>1.038260</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990150</td>\n",
       "      <td>0.990064</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss      recon        kl  mmd   val_loss  val_recon    val_kl  \\\n",
       "0   54.892296  53.577824  1.314364  0.0  12.177666  10.952815  1.224849   \n",
       "1    8.350660   7.316357  1.034306  0.0   6.661676   5.624257  1.037420   \n",
       "2    5.126224   4.324258  0.801971  0.0   4.507024   3.701198  0.805828   \n",
       "3    3.464654   2.888922  0.575735  0.0   2.889389   2.386144  0.503246   \n",
       "4    2.440433   2.065762  0.374671  0.0   2.128606   1.792644  0.335962   \n",
       "5    1.823447   1.609350  0.214099  0.0   1.583832   1.406919  0.176913   \n",
       "6    1.460065   1.350541  0.109524  0.0   1.317115   1.222072  0.095043   \n",
       "7    1.269654   1.213995  0.055659  0.0   1.171761   1.124651  0.047110   \n",
       "8    1.172160   1.139324  0.032835  0.0   1.103393   1.067432  0.035960   \n",
       "9    1.120640   1.098759  0.021882  0.0   1.061594   1.038763  0.022832   \n",
       "10   1.090864   1.076697  0.014166  0.0   1.036398   1.020974  0.015424   \n",
       "11   1.072605   1.064643  0.007963  0.0   1.039127   1.011789  0.027338   \n",
       "12   1.060933   1.057243  0.003690  0.0   1.032781   1.006457  0.026324   \n",
       "13   1.054316   1.052867  0.001448  0.0   1.115550   1.005274  0.110276   \n",
       "14   1.050584   1.049993  0.000590  0.0   1.110064   1.001574  0.108491   \n",
       "15   1.048113   1.047774  0.000340  0.0   1.131331   1.000406  0.130925   \n",
       "16   1.046701   1.046438  0.000262  0.0   1.196488   0.999532  0.196956   \n",
       "17   1.045563   1.045336  0.000226  0.0   1.079571   0.997354  0.082217   \n",
       "18   1.044625   1.044424  0.000201  0.0   1.147773   0.996725  0.151047   \n",
       "19   1.044149   1.043969  0.000180  0.0   1.139311   0.995452  0.143859   \n",
       "20   1.043407   1.043251  0.000155  0.0   1.121268   0.995662  0.125607   \n",
       "21   1.043007   1.042871  0.000137  0.0   1.121299   0.994750  0.126550   \n",
       "22   1.042669   1.042547  0.000121  0.0   1.153478   0.993144  0.160335   \n",
       "23   1.042414   1.042306  0.000108  0.0   1.183293   0.995011  0.188282   \n",
       "24   1.042008   1.041911  0.000097  0.0   1.043247   0.993954  0.049292   \n",
       "25   1.041754   1.041670  0.000084  0.0   1.028952   0.992582  0.036369   \n",
       "26   1.041455   1.041380  0.000076  0.0   1.013046   0.993216  0.019830   \n",
       "27   1.041185   1.041120  0.000065  0.0   1.008431   0.993690  0.014741   \n",
       "28   1.040969   1.040913  0.000056  0.0   0.998486   0.992193  0.006293   \n",
       "29   1.040797   1.040749  0.000047  0.0   0.998303   0.992786  0.005516   \n",
       "30   1.040649   1.040609  0.000040  0.0   0.994916   0.991644  0.003272   \n",
       "31   1.040385   1.040349  0.000036  0.0   0.994397   0.992904  0.001494   \n",
       "32   1.040267   1.040236  0.000031  0.0   0.994891   0.992291  0.002600   \n",
       "33   1.040143   1.040116  0.000028  0.0   0.992281   0.991340  0.000942   \n",
       "34   1.039915   1.039889  0.000026  0.0   0.992211   0.991435  0.000777   \n",
       "35   1.039779   1.039755  0.000024  0.0   0.992571   0.991725  0.000846   \n",
       "36   1.039642   1.039619  0.000022  0.0   0.991664   0.991203  0.000461   \n",
       "37   1.039596   1.039576  0.000021  0.0   0.991449   0.990797  0.000652   \n",
       "38   1.039450   1.039431  0.000019  0.0   0.991404   0.991043  0.000361   \n",
       "39   1.039266   1.039248  0.000017  0.0   0.991717   0.991431  0.000287   \n",
       "40   1.039165   1.039149  0.000016  0.0   0.990233   0.990016  0.000217   \n",
       "41   1.039062   1.039048  0.000015  0.0   0.990392   0.990237  0.000155   \n",
       "42   1.039017   1.039001  0.000014  0.0   0.991719   0.991596  0.000123   \n",
       "43   1.038949   1.038936  0.000014  0.0   0.990852   0.990730  0.000123   \n",
       "44   1.038826   1.038813  0.000013  0.0   0.991205   0.991109  0.000097   \n",
       "45   1.038746   1.038733  0.000012  0.0   0.989452   0.989347  0.000105   \n",
       "46   1.038569   1.038557  0.000012  0.0   0.989588   0.989486  0.000102   \n",
       "47   1.038548   1.038537  0.000012  0.0   0.989657   0.989563  0.000094   \n",
       "48   1.038553   1.038542  0.000011  0.0   0.990145   0.990020  0.000125   \n",
       "49   1.038270   1.038260  0.000010  0.0   0.990150   0.990064  0.000085   \n",
       "\n",
       "    val_mmd  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "5       0.0  \n",
       "6       0.0  \n",
       "7       0.0  \n",
       "8       0.0  \n",
       "9       0.0  \n",
       "10      0.0  \n",
       "11      0.0  \n",
       "12      0.0  \n",
       "13      0.0  \n",
       "14      0.0  \n",
       "15      0.0  \n",
       "16      0.0  \n",
       "17      0.0  \n",
       "18      0.0  \n",
       "19      0.0  \n",
       "20      0.0  \n",
       "21      0.0  \n",
       "22      0.0  \n",
       "23      0.0  \n",
       "24      0.0  \n",
       "25      0.0  \n",
       "26      0.0  \n",
       "27      0.0  \n",
       "28      0.0  \n",
       "29      0.0  \n",
       "30      0.0  \n",
       "31      0.0  \n",
       "32      0.0  \n",
       "33      0.0  \n",
       "34      0.0  \n",
       "35      0.0  \n",
       "36      0.0  \n",
       "37      0.0  \n",
       "38      0.0  \n",
       "39      0.0  \n",
       "40      0.0  \n",
       "41      0.0  \n",
       "42      0.0  \n",
       "43      0.0  \n",
       "44      0.0  \n",
       "45      0.0  \n",
       "46      0.0  \n",
       "47      0.0  \n",
       "48      0.0  \n",
       "49      0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save training performance\n",
    "history_df = pd.DataFrame(cp_vae.vae.history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2080dce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 02:16:45.787950: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/level4EncoderShuffled_beta/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/level4DecoderShuffled_beta/assets\n"
     ]
    }
   ],
   "source": [
    "encoder = cp_vae.encoder_block[\"encoder\"]\n",
    "decoder = cp_vae.decoder_block[\"decoder\"]\n",
    "encoder.save(\"models/level4EncoderShuffled_beta\")\n",
    "decoder.save(\"models/level4DecoderShuffled_beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0d167dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_df.to_csv('level4_training_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d4d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_df = pd.read_csv('level4_training_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371be6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_training_data  = pd.read_csv('level4_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3b2d259",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7, 5), dpi = 400)\n",
    "# plt.plot(original_training_data[\"loss\"], label=\"Training data\")\n",
    "# plt.plot(original_training_data[\"val_loss\"], label=\"Validation data\")\n",
    "# plt.plot(history_df[\"loss\"], label=\"Shuffled training data\")\n",
    "# plt.plot(history_df[\"val_loss\"], label=\"Shuffled validation data\")\n",
    "# # plt.title(\"Loss for VAE training on Cell Painting Level 5 data\")\n",
    "# plt.ylabel(\"MSE + KL Divergence\")\n",
    "# plt.xlabel(\"No. Epoch\")\n",
    "# plt.ylim(0,5)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7841eb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "cp_vae = VAE(\n",
    "    input_dim=train_features_df.shape[1],\n",
    "    latent_dim=90,\n",
    "    batch_size=32,\n",
    "    encoder_batch_norm=True,\n",
    "    epochs=58,\n",
    "    learning_rate=0.0001,\n",
    "    encoder_architecture=encoder_architecture,\n",
    "    decoder_architecture=decoder_architecture,\n",
    "    beta=1,\n",
    "    verbose=True,\n",
    ")\n",
    "cp_vae.compile_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2541ec3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/58\n",
      "1258/1258 [==============================] - 11s 6ms/step - loss: 70.3704 - recon: 52.7581 - kl: 17.6124 - mmd: 0.0000e+00 - val_loss: 26.5960 - val_recon: 10.9781 - val_kl: 15.6180 - val_mmd: 0.0000e+00\n",
      "Epoch 2/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.5164 - recon: 6.5975 - kl: 5.9189 - mmd: 0.0000e+00 - val_loss: 8.1625 - val_recon: 4.6823 - val_kl: 3.4802 - val_mmd: 0.0000e+00\n",
      "Epoch 3/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 5.2896 - recon: 3.8543 - kl: 1.4354 - mmd: 0.0000e+00 - val_loss: 4.0096 - val_recon: 3.0823 - val_kl: 0.9273 - val_mmd: 0.0000e+00\n",
      "Epoch 4/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 3.1639 - recon: 2.7058 - kl: 0.4581 - mmd: 0.0000e+00 - val_loss: 2.7240 - val_recon: 2.2602 - val_kl: 0.4638 - val_mmd: 0.0000e+00\n",
      "Epoch 5/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 2.2694 - recon: 2.0354 - kl: 0.2340 - mmd: 0.0000e+00 - val_loss: 2.0295 - val_recon: 1.7513 - val_kl: 0.2782 - val_mmd: 0.0000e+00\n",
      "Epoch 6/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.7610 - recon: 1.6263 - kl: 0.1347 - mmd: 0.0000e+00 - val_loss: 1.6175 - val_recon: 1.4457 - val_kl: 0.1718 - val_mmd: 0.0000e+00\n",
      "Epoch 7/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.4538 - recon: 1.3829 - kl: 0.0710 - mmd: 0.0000e+00 - val_loss: 1.3913 - val_recon: 1.2517 - val_kl: 0.1396 - val_mmd: 0.0000e+00\n",
      "Epoch 8/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.2724 - recon: 1.2409 - kl: 0.0315 - mmd: 0.0000e+00 - val_loss: 1.5551 - val_recon: 1.1503 - val_kl: 0.4048 - val_mmd: 0.0000e+00\n",
      "Epoch 9/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.1695 - recon: 1.1585 - kl: 0.0111 - mmd: 0.0000e+00 - val_loss: 3.1041 - val_recon: 1.1104 - val_kl: 1.9938 - val_mmd: 0.0000e+00\n",
      "Epoch 10/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.1131 - recon: 1.1098 - kl: 0.0033 - mmd: 0.0000e+00 - val_loss: 1.2312 - val_recon: 1.0450 - val_kl: 0.1862 - val_mmd: 0.0000e+00\n",
      "Epoch 11/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0831 - recon: 1.0819 - kl: 0.0012 - mmd: 0.0000e+00 - val_loss: 1.4182 - val_recon: 1.0269 - val_kl: 0.3913 - val_mmd: 0.0000e+00\n",
      "Epoch 12/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0675 - recon: 1.0666 - kl: 9.0348e-04 - mmd: 0.0000e+00 - val_loss: 1.3450 - val_recon: 1.0138 - val_kl: 0.3311 - val_mmd: 0.0000e+00\n",
      "Epoch 13/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0589 - recon: 1.0579 - kl: 9.9269e-04 - mmd: 0.0000e+00 - val_loss: 1.2966 - val_recon: 1.0058 - val_kl: 0.2908 - val_mmd: 0.0000e+00\n",
      "Epoch 14/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0539 - recon: 1.0530 - kl: 8.8816e-04 - mmd: 0.0000e+00 - val_loss: 1.4469 - val_recon: 1.0045 - val_kl: 0.4424 - val_mmd: 0.0000e+00\n",
      "Epoch 15/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0509 - recon: 1.0501 - kl: 8.8119e-04 - mmd: 0.0000e+00 - val_loss: 1.2821 - val_recon: 1.0024 - val_kl: 0.2797 - val_mmd: 0.0000e+00\n",
      "Epoch 16/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0490 - recon: 1.0483 - kl: 6.9206e-04 - mmd: 0.0000e+00 - val_loss: 1.2277 - val_recon: 0.9996 - val_kl: 0.2281 - val_mmd: 0.0000e+00\n",
      "Epoch 17/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0476 - recon: 1.0471 - kl: 5.6050e-04 - mmd: 0.0000e+00 - val_loss: 1.3975 - val_recon: 0.9982 - val_kl: 0.3993 - val_mmd: 0.0000e+00\n",
      "Epoch 18/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0465 - recon: 1.0461 - kl: 4.3724e-04 - mmd: 0.0000e+00 - val_loss: 1.1560 - val_recon: 0.9962 - val_kl: 0.1597 - val_mmd: 0.0000e+00\n",
      "Epoch 19/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0456 - recon: 1.0453 - kl: 3.2385e-04 - mmd: 0.0000e+00 - val_loss: 1.1265 - val_recon: 0.9971 - val_kl: 0.1294 - val_mmd: 0.0000e+00\n",
      "Epoch 20/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0450 - recon: 1.0448 - kl: 2.1821e-04 - mmd: 0.0000e+00 - val_loss: 1.0928 - val_recon: 0.9963 - val_kl: 0.0965 - val_mmd: 0.0000e+00\n",
      "Epoch 21/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0445 - recon: 1.0443 - kl: 1.4267e-04 - mmd: 0.0000e+00 - val_loss: 1.0655 - val_recon: 0.9956 - val_kl: 0.0699 - val_mmd: 0.0000e+00\n",
      "Epoch 22/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0440 - recon: 1.0440 - kl: 8.7057e-05 - mmd: 0.0000e+00 - val_loss: 1.0617 - val_recon: 0.9962 - val_kl: 0.0654 - val_mmd: 0.0000e+00\n",
      "Epoch 23/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0436 - recon: 1.0436 - kl: 5.2125e-05 - mmd: 0.0000e+00 - val_loss: 1.0318 - val_recon: 0.9942 - val_kl: 0.0375 - val_mmd: 0.0000e+00\n",
      "Epoch 24/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0432 - recon: 1.0432 - kl: 3.0372e-05 - mmd: 0.0000e+00 - val_loss: 1.0211 - val_recon: 0.9940 - val_kl: 0.0272 - val_mmd: 0.0000e+00\n",
      "Epoch 25/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0429 - recon: 1.0429 - kl: 1.7190e-05 - mmd: 0.0000e+00 - val_loss: 1.0126 - val_recon: 0.9955 - val_kl: 0.0171 - val_mmd: 0.0000e+00\n",
      "Epoch 26/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0425 - recon: 1.0425 - kl: 9.2479e-06 - mmd: 0.0000e+00 - val_loss: 0.9990 - val_recon: 0.9944 - val_kl: 0.0046 - val_mmd: 0.0000e+00\n",
      "Epoch 27/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0423 - recon: 1.0423 - kl: 4.9868e-06 - mmd: 0.0000e+00 - val_loss: 0.9957 - val_recon: 0.9938 - val_kl: 0.0019 - val_mmd: 0.0000e+00\n",
      "Epoch 28/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0421 - recon: 1.0421 - kl: 3.1160e-06 - mmd: 0.0000e+00 - val_loss: 0.9950 - val_recon: 0.9943 - val_kl: 6.8286e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 29/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0418 - recon: 1.0418 - kl: 2.3726e-06 - mmd: 0.0000e+00 - val_loss: 0.9932 - val_recon: 0.9929 - val_kl: 2.6765e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 30/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0418 - recon: 1.0418 - kl: 1.9883e-06 - mmd: 0.0000e+00 - val_loss: 0.9934 - val_recon: 0.9932 - val_kl: 1.4914e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 31/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0414 - recon: 1.0414 - kl: 1.8429e-06 - mmd: 0.0000e+00 - val_loss: 0.9928 - val_recon: 0.9927 - val_kl: 9.0420e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 32/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0413 - recon: 1.0413 - kl: 1.7658e-06 - mmd: 0.0000e+00 - val_loss: 0.9934 - val_recon: 0.9931 - val_kl: 2.6488e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 33/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0410 - recon: 1.0410 - kl: 1.6574e-06 - mmd: 0.0000e+00 - val_loss: 0.9932 - val_recon: 0.9931 - val_kl: 1.2419e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 34/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0408 - recon: 1.0408 - kl: 1.5263e-06 - mmd: 0.0000e+00 - val_loss: 0.9922 - val_recon: 0.9921 - val_kl: 7.3812e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 35/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0407 - recon: 1.0407 - kl: 1.4098e-06 - mmd: 0.0000e+00 - val_loss: 0.9936 - val_recon: 0.9935 - val_kl: 1.0100e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 36/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0405 - recon: 1.0405 - kl: 1.2648e-06 - mmd: 0.0000e+00 - val_loss: 0.9914 - val_recon: 0.9913 - val_kl: 6.1356e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 37/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0404 - recon: 1.0404 - kl: 1.2432e-06 - mmd: 0.0000e+00 - val_loss: 0.9930 - val_recon: 0.9930 - val_kl: 5.5066e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 38/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0402 - recon: 1.0402 - kl: 1.0966e-06 - mmd: 0.0000e+00 - val_loss: 0.9911 - val_recon: 0.9911 - val_kl: 3.9630e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 39/58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0401 - recon: 1.0401 - kl: 1.0280e-06 - mmd: 0.0000e+00 - val_loss: 0.9921 - val_recon: 0.9920 - val_kl: 6.3616e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 40/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0400 - recon: 1.0400 - kl: 1.0544e-06 - mmd: 0.0000e+00 - val_loss: 0.9919 - val_recon: 0.9919 - val_kl: 3.2176e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 41/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0399 - recon: 1.0399 - kl: 9.3989e-07 - mmd: 0.0000e+00 - val_loss: 0.9917 - val_recon: 0.9917 - val_kl: 4.9938e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 42/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0399 - recon: 1.0399 - kl: 8.8792e-07 - mmd: 0.0000e+00 - val_loss: 0.9906 - val_recon: 0.9906 - val_kl: 1.2076e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 43/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0396 - recon: 1.0396 - kl: 8.4685e-07 - mmd: 0.0000e+00 - val_loss: 0.9920 - val_recon: 0.9920 - val_kl: 2.0598e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 44/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0395 - recon: 1.0395 - kl: 8.0385e-07 - mmd: 0.0000e+00 - val_loss: 0.9913 - val_recon: 0.9913 - val_kl: 1.8646e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 45/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0395 - recon: 1.0395 - kl: 7.5577e-07 - mmd: 0.0000e+00 - val_loss: 0.9908 - val_recon: 0.9908 - val_kl: 3.1372e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 46/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0392 - recon: 1.0392 - kl: 7.4204e-07 - mmd: 0.0000e+00 - val_loss: 0.9909 - val_recon: 0.9909 - val_kl: 2.2972e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 47/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0393 - recon: 1.0393 - kl: 6.5899e-07 - mmd: 0.0000e+00 - val_loss: 0.9901 - val_recon: 0.9901 - val_kl: 1.2941e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 48/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0391 - recon: 1.0391 - kl: 6.0571e-07 - mmd: 0.0000e+00 - val_loss: 0.9916 - val_recon: 0.9915 - val_kl: 4.4393e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 49/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0392 - recon: 1.0392 - kl: 6.4776e-07 - mmd: 0.0000e+00 - val_loss: 0.9904 - val_recon: 0.9904 - val_kl: 1.5480e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 50/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0390 - recon: 1.0390 - kl: 6.5965e-07 - mmd: 0.0000e+00 - val_loss: 0.9901 - val_recon: 0.9901 - val_kl: 1.4391e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 51/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0389 - recon: 1.0389 - kl: 6.6303e-07 - mmd: 0.0000e+00 - val_loss: 0.9903 - val_recon: 0.9902 - val_kl: 7.0549e-06 - val_mmd: 0.0000e+00\n",
      "Epoch 52/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0389 - recon: 1.0389 - kl: 6.1294e-07 - mmd: 0.0000e+00 - val_loss: 0.9903 - val_recon: 0.9903 - val_kl: 9.1154e-06 - val_mmd: 0.0000e+00\n",
      "Epoch 53/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0387 - recon: 1.0387 - kl: 5.9638e-07 - mmd: 0.0000e+00 - val_loss: 0.9894 - val_recon: 0.9894 - val_kl: 9.9307e-06 - val_mmd: 0.0000e+00\n",
      "Epoch 54/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0387 - recon: 1.0387 - kl: 5.9722e-07 - mmd: 0.0000e+00 - val_loss: 0.9904 - val_recon: 0.9903 - val_kl: 4.4189e-06 - val_mmd: 0.0000e+00\n",
      "Epoch 55/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0386 - recon: 1.0386 - kl: 5.2476e-07 - mmd: 0.0000e+00 - val_loss: 0.9901 - val_recon: 0.9901 - val_kl: 1.0201e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 56/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0385 - recon: 1.0385 - kl: 5.6475e-07 - mmd: 0.0000e+00 - val_loss: 0.9900 - val_recon: 0.9900 - val_kl: 1.5534e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 57/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0384 - recon: 1.0384 - kl: 5.5263e-07 - mmd: 0.0000e+00 - val_loss: 0.9892 - val_recon: 0.9892 - val_kl: 8.4226e-06 - val_mmd: 0.0000e+00\n",
      "Epoch 58/58\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 1.0383 - recon: 1.0383 - kl: 5.4674e-07 - mmd: 0.0000e+00 - val_loss: 0.9911 - val_recon: 0.9911 - val_kl: 1.0081e-05 - val_mmd: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "cp_vae.train(x_train=train_features_df, x_test=valid_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31e7e53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fa70af931d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_vae.vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74c4e6ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recon</th>\n",
       "      <th>kl</th>\n",
       "      <th>mmd</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recon</th>\n",
       "      <th>val_kl</th>\n",
       "      <th>val_mmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.370407</td>\n",
       "      <td>52.758076</td>\n",
       "      <td>1.761240e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.596024</td>\n",
       "      <td>10.978057</td>\n",
       "      <td>15.617961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.516389</td>\n",
       "      <td>6.597512</td>\n",
       "      <td>5.918881e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.162502</td>\n",
       "      <td>4.682303</td>\n",
       "      <td>3.480198</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.289619</td>\n",
       "      <td>3.854258</td>\n",
       "      <td>1.435357e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.009625</td>\n",
       "      <td>3.082335</td>\n",
       "      <td>0.927292</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.163886</td>\n",
       "      <td>2.705787</td>\n",
       "      <td>4.581015e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.723989</td>\n",
       "      <td>2.260216</td>\n",
       "      <td>0.463773</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.269424</td>\n",
       "      <td>2.035388</td>\n",
       "      <td>2.340383e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.029506</td>\n",
       "      <td>1.751306</td>\n",
       "      <td>0.278200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.760998</td>\n",
       "      <td>1.626251</td>\n",
       "      <td>1.347477e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.617525</td>\n",
       "      <td>1.445691</td>\n",
       "      <td>0.171833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.453811</td>\n",
       "      <td>1.382861</td>\n",
       "      <td>7.095001e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.391315</td>\n",
       "      <td>1.251676</td>\n",
       "      <td>0.139638</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.272382</td>\n",
       "      <td>1.240887</td>\n",
       "      <td>3.149613e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.555143</td>\n",
       "      <td>1.150310</td>\n",
       "      <td>0.404834</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.169523</td>\n",
       "      <td>1.158463</td>\n",
       "      <td>1.106157e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.104126</td>\n",
       "      <td>1.110373</td>\n",
       "      <td>1.993753</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.113103</td>\n",
       "      <td>1.109824</td>\n",
       "      <td>3.279684e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.231197</td>\n",
       "      <td>1.045007</td>\n",
       "      <td>0.186190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.083076</td>\n",
       "      <td>1.081884</td>\n",
       "      <td>1.192416e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.418228</td>\n",
       "      <td>1.026883</td>\n",
       "      <td>0.391345</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.067544</td>\n",
       "      <td>1.066642</td>\n",
       "      <td>9.034794e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344954</td>\n",
       "      <td>1.013807</td>\n",
       "      <td>0.331147</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.058850</td>\n",
       "      <td>1.057857</td>\n",
       "      <td>9.926857e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.296602</td>\n",
       "      <td>1.005816</td>\n",
       "      <td>0.290787</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.053920</td>\n",
       "      <td>1.053033</td>\n",
       "      <td>8.881647e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.446895</td>\n",
       "      <td>1.004508</td>\n",
       "      <td>0.442386</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.050946</td>\n",
       "      <td>1.050065</td>\n",
       "      <td>8.811909e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.282072</td>\n",
       "      <td>1.002382</td>\n",
       "      <td>0.279690</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.048961</td>\n",
       "      <td>1.048268</td>\n",
       "      <td>6.920567e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.227707</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.228091</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.047629</td>\n",
       "      <td>1.047068</td>\n",
       "      <td>5.604979e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.397477</td>\n",
       "      <td>0.998201</td>\n",
       "      <td>0.399276</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.046519</td>\n",
       "      <td>1.046082</td>\n",
       "      <td>4.372415e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.155957</td>\n",
       "      <td>0.996230</td>\n",
       "      <td>0.159728</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.045640</td>\n",
       "      <td>1.045316</td>\n",
       "      <td>3.238468e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.126476</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.129358</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.045014</td>\n",
       "      <td>1.044796</td>\n",
       "      <td>2.182090e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.092789</td>\n",
       "      <td>0.996314</td>\n",
       "      <td>0.096475</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.044493</td>\n",
       "      <td>1.044349</td>\n",
       "      <td>1.426731e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.065461</td>\n",
       "      <td>0.995563</td>\n",
       "      <td>0.069898</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.044040</td>\n",
       "      <td>1.043953</td>\n",
       "      <td>8.705672e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.061653</td>\n",
       "      <td>0.996242</td>\n",
       "      <td>0.065411</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.043607</td>\n",
       "      <td>1.043557</td>\n",
       "      <td>5.212511e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.031756</td>\n",
       "      <td>0.994228</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.043183</td>\n",
       "      <td>1.043151</td>\n",
       "      <td>3.037215e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.021123</td>\n",
       "      <td>0.993965</td>\n",
       "      <td>0.027158</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.042886</td>\n",
       "      <td>1.042868</td>\n",
       "      <td>1.718965e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.012579</td>\n",
       "      <td>0.995471</td>\n",
       "      <td>0.017108</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.042539</td>\n",
       "      <td>1.042530</td>\n",
       "      <td>9.247903e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998981</td>\n",
       "      <td>0.994401</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.042286</td>\n",
       "      <td>1.042282</td>\n",
       "      <td>4.986766e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995664</td>\n",
       "      <td>0.993764</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.042116</td>\n",
       "      <td>1.042112</td>\n",
       "      <td>3.116026e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995016</td>\n",
       "      <td>0.994333</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.041823</td>\n",
       "      <td>1.041821</td>\n",
       "      <td>2.372576e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993209</td>\n",
       "      <td>0.992941</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.041791</td>\n",
       "      <td>1.041790</td>\n",
       "      <td>1.988306e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993370</td>\n",
       "      <td>0.993221</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.041390</td>\n",
       "      <td>1.041388</td>\n",
       "      <td>1.842903e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992797</td>\n",
       "      <td>0.992706</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.041259</td>\n",
       "      <td>1.041257</td>\n",
       "      <td>1.765803e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993376</td>\n",
       "      <td>0.993111</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.040972</td>\n",
       "      <td>1.040970</td>\n",
       "      <td>1.657449e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993231</td>\n",
       "      <td>0.993107</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.040797</td>\n",
       "      <td>1.040796</td>\n",
       "      <td>1.526255e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992210</td>\n",
       "      <td>0.992136</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.040703</td>\n",
       "      <td>1.040702</td>\n",
       "      <td>1.409803e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993596</td>\n",
       "      <td>0.993495</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.040505</td>\n",
       "      <td>1.040504</td>\n",
       "      <td>1.264792e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991410</td>\n",
       "      <td>0.991349</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.040357</td>\n",
       "      <td>1.040356</td>\n",
       "      <td>1.243212e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993041</td>\n",
       "      <td>0.992986</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.040210</td>\n",
       "      <td>1.040209</td>\n",
       "      <td>1.096550e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991124</td>\n",
       "      <td>0.991085</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.040130</td>\n",
       "      <td>1.040130</td>\n",
       "      <td>1.027970e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992069</td>\n",
       "      <td>0.992005</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.039958</td>\n",
       "      <td>1.039957</td>\n",
       "      <td>1.054411e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991886</td>\n",
       "      <td>0.991853</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.039905</td>\n",
       "      <td>1.039904</td>\n",
       "      <td>9.398929e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991704</td>\n",
       "      <td>0.991654</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.039894</td>\n",
       "      <td>1.039893</td>\n",
       "      <td>8.879229e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990595</td>\n",
       "      <td>0.990583</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.039607</td>\n",
       "      <td>1.039606</td>\n",
       "      <td>8.468483e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992007</td>\n",
       "      <td>0.991987</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.039539</td>\n",
       "      <td>1.039538</td>\n",
       "      <td>8.038510e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991320</td>\n",
       "      <td>0.991301</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.039462</td>\n",
       "      <td>1.039462</td>\n",
       "      <td>7.557742e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990824</td>\n",
       "      <td>0.990792</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.039185</td>\n",
       "      <td>1.039185</td>\n",
       "      <td>7.420387e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990898</td>\n",
       "      <td>0.990875</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.039272</td>\n",
       "      <td>1.039272</td>\n",
       "      <td>6.589859e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990090</td>\n",
       "      <td>0.990077</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.039146</td>\n",
       "      <td>1.039145</td>\n",
       "      <td>6.057147e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991577</td>\n",
       "      <td>0.991533</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.039199</td>\n",
       "      <td>1.039199</td>\n",
       "      <td>6.477595e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990367</td>\n",
       "      <td>0.990352</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.039033</td>\n",
       "      <td>1.039033</td>\n",
       "      <td>6.596472e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990107</td>\n",
       "      <td>0.990093</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.038920</td>\n",
       "      <td>1.038919</td>\n",
       "      <td>6.630310e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990256</td>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.038945</td>\n",
       "      <td>1.038944</td>\n",
       "      <td>6.129442e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990315</td>\n",
       "      <td>0.990306</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.038745</td>\n",
       "      <td>1.038745</td>\n",
       "      <td>5.963753e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989434</td>\n",
       "      <td>0.989424</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.038706</td>\n",
       "      <td>1.038706</td>\n",
       "      <td>5.972158e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990351</td>\n",
       "      <td>0.990347</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.038552</td>\n",
       "      <td>1.038551</td>\n",
       "      <td>5.247607e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.990138</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.038485</td>\n",
       "      <td>1.038485</td>\n",
       "      <td>5.647526e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990004</td>\n",
       "      <td>0.989989</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.038391</td>\n",
       "      <td>1.038391</td>\n",
       "      <td>5.526271e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989168</td>\n",
       "      <td>0.989160</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.038304</td>\n",
       "      <td>1.038304</td>\n",
       "      <td>5.467396e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991070</td>\n",
       "      <td>0.991059</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss      recon            kl  mmd   val_loss  val_recon     val_kl  \\\n",
       "0   70.370407  52.758076  1.761240e+01  0.0  26.596024  10.978057  15.617961   \n",
       "1   12.516389   6.597512  5.918881e+00  0.0   8.162502   4.682303   3.480198   \n",
       "2    5.289619   3.854258  1.435357e+00  0.0   4.009625   3.082335   0.927292   \n",
       "3    3.163886   2.705787  4.581015e-01  0.0   2.723989   2.260216   0.463773   \n",
       "4    2.269424   2.035388  2.340383e-01  0.0   2.029506   1.751306   0.278200   \n",
       "5    1.760998   1.626251  1.347477e-01  0.0   1.617525   1.445691   0.171833   \n",
       "6    1.453811   1.382861  7.095001e-02  0.0   1.391315   1.251676   0.139638   \n",
       "7    1.272382   1.240887  3.149613e-02  0.0   1.555143   1.150310   0.404834   \n",
       "8    1.169523   1.158463  1.106157e-02  0.0   3.104126   1.110373   1.993753   \n",
       "9    1.113103   1.109824  3.279684e-03  0.0   1.231197   1.045007   0.186190   \n",
       "10   1.083076   1.081884  1.192416e-03  0.0   1.418228   1.026883   0.391345   \n",
       "11   1.067544   1.066642  9.034794e-04  0.0   1.344954   1.013807   0.331147   \n",
       "12   1.058850   1.057857  9.926857e-04  0.0   1.296602   1.005816   0.290787   \n",
       "13   1.053920   1.053033  8.881647e-04  0.0   1.446895   1.004508   0.442386   \n",
       "14   1.050946   1.050065  8.811909e-04  0.0   1.282072   1.002382   0.279690   \n",
       "15   1.048961   1.048268  6.920567e-04  0.0   1.227707   0.999616   0.228091   \n",
       "16   1.047629   1.047068  5.604979e-04  0.0   1.397477   0.998201   0.399276   \n",
       "17   1.046519   1.046082  4.372415e-04  0.0   1.155957   0.996230   0.159728   \n",
       "18   1.045640   1.045316  3.238468e-04  0.0   1.126476   0.997118   0.129358   \n",
       "19   1.045014   1.044796  2.182090e-04  0.0   1.092789   0.996314   0.096475   \n",
       "20   1.044493   1.044349  1.426731e-04  0.0   1.065461   0.995563   0.069898   \n",
       "21   1.044040   1.043953  8.705672e-05  0.0   1.061653   0.996242   0.065411   \n",
       "22   1.043607   1.043557  5.212511e-05  0.0   1.031756   0.994228   0.037528   \n",
       "23   1.043183   1.043151  3.037215e-05  0.0   1.021123   0.993965   0.027158   \n",
       "24   1.042886   1.042868  1.718965e-05  0.0   1.012579   0.995471   0.017108   \n",
       "25   1.042539   1.042530  9.247903e-06  0.0   0.998981   0.994401   0.004580   \n",
       "26   1.042286   1.042282  4.986766e-06  0.0   0.995664   0.993764   0.001900   \n",
       "27   1.042116   1.042112  3.116026e-06  0.0   0.995016   0.994333   0.000683   \n",
       "28   1.041823   1.041821  2.372576e-06  0.0   0.993209   0.992941   0.000268   \n",
       "29   1.041791   1.041790  1.988306e-06  0.0   0.993370   0.993221   0.000149   \n",
       "30   1.041390   1.041388  1.842903e-06  0.0   0.992797   0.992706   0.000090   \n",
       "31   1.041259   1.041257  1.765803e-06  0.0   0.993376   0.993111   0.000265   \n",
       "32   1.040972   1.040970  1.657449e-06  0.0   0.993231   0.993107   0.000124   \n",
       "33   1.040797   1.040796  1.526255e-06  0.0   0.992210   0.992136   0.000074   \n",
       "34   1.040703   1.040702  1.409803e-06  0.0   0.993596   0.993495   0.000101   \n",
       "35   1.040505   1.040504  1.264792e-06  0.0   0.991410   0.991349   0.000061   \n",
       "36   1.040357   1.040356  1.243212e-06  0.0   0.993041   0.992986   0.000055   \n",
       "37   1.040210   1.040209  1.096550e-06  0.0   0.991124   0.991085   0.000040   \n",
       "38   1.040130   1.040130  1.027970e-06  0.0   0.992069   0.992005   0.000064   \n",
       "39   1.039958   1.039957  1.054411e-06  0.0   0.991886   0.991853   0.000032   \n",
       "40   1.039905   1.039904  9.398929e-07  0.0   0.991704   0.991654   0.000050   \n",
       "41   1.039894   1.039893  8.879229e-07  0.0   0.990595   0.990583   0.000012   \n",
       "42   1.039607   1.039606  8.468483e-07  0.0   0.992007   0.991987   0.000021   \n",
       "43   1.039539   1.039538  8.038510e-07  0.0   0.991320   0.991301   0.000019   \n",
       "44   1.039462   1.039462  7.557742e-07  0.0   0.990824   0.990792   0.000031   \n",
       "45   1.039185   1.039185  7.420387e-07  0.0   0.990898   0.990875   0.000023   \n",
       "46   1.039272   1.039272  6.589859e-07  0.0   0.990090   0.990077   0.000013   \n",
       "47   1.039146   1.039145  6.057147e-07  0.0   0.991577   0.991533   0.000044   \n",
       "48   1.039199   1.039199  6.477595e-07  0.0   0.990367   0.990352   0.000015   \n",
       "49   1.039033   1.039033  6.596472e-07  0.0   0.990107   0.990093   0.000014   \n",
       "50   1.038920   1.038919  6.630310e-07  0.0   0.990256   0.990249   0.000007   \n",
       "51   1.038945   1.038944  6.129442e-07  0.0   0.990315   0.990306   0.000009   \n",
       "52   1.038745   1.038745  5.963753e-07  0.0   0.989434   0.989424   0.000010   \n",
       "53   1.038706   1.038706  5.972158e-07  0.0   0.990351   0.990347   0.000004   \n",
       "54   1.038552   1.038551  5.247607e-07  0.0   0.990148   0.990138   0.000010   \n",
       "55   1.038485   1.038485  5.647526e-07  0.0   0.990004   0.989989   0.000016   \n",
       "56   1.038391   1.038391  5.526271e-07  0.0   0.989168   0.989160   0.000008   \n",
       "57   1.038304   1.038304  5.467396e-07  0.0   0.991070   0.991059   0.000010   \n",
       "\n",
       "    val_mmd  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "5       0.0  \n",
       "6       0.0  \n",
       "7       0.0  \n",
       "8       0.0  \n",
       "9       0.0  \n",
       "10      0.0  \n",
       "11      0.0  \n",
       "12      0.0  \n",
       "13      0.0  \n",
       "14      0.0  \n",
       "15      0.0  \n",
       "16      0.0  \n",
       "17      0.0  \n",
       "18      0.0  \n",
       "19      0.0  \n",
       "20      0.0  \n",
       "21      0.0  \n",
       "22      0.0  \n",
       "23      0.0  \n",
       "24      0.0  \n",
       "25      0.0  \n",
       "26      0.0  \n",
       "27      0.0  \n",
       "28      0.0  \n",
       "29      0.0  \n",
       "30      0.0  \n",
       "31      0.0  \n",
       "32      0.0  \n",
       "33      0.0  \n",
       "34      0.0  \n",
       "35      0.0  \n",
       "36      0.0  \n",
       "37      0.0  \n",
       "38      0.0  \n",
       "39      0.0  \n",
       "40      0.0  \n",
       "41      0.0  \n",
       "42      0.0  \n",
       "43      0.0  \n",
       "44      0.0  \n",
       "45      0.0  \n",
       "46      0.0  \n",
       "47      0.0  \n",
       "48      0.0  \n",
       "49      0.0  \n",
       "50      0.0  \n",
       "51      0.0  \n",
       "52      0.0  \n",
       "53      0.0  \n",
       "54      0.0  \n",
       "55      0.0  \n",
       "56      0.0  \n",
       "57      0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save training performance\n",
    "history_df = pd.DataFrame(cp_vae.vae.history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c255ae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/level4EncoderShuffled_vanilla/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/level4DecoderShuffled_vanilla/assets\n"
     ]
    }
   ],
   "source": [
    "encoder = cp_vae.encoder_block[\"encoder\"]\n",
    "decoder = cp_vae.decoder_block[\"decoder\"]\n",
    "encoder.save(\"models/level4EncoderShuffled_vanilla\")\n",
    "decoder.save(\"models/level4DecoderShuffled_vanilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b80badd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_df.to_csv('level4_training_vanilla_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2e679f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_df = pd.read_csv('level4_training_vanilla_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2fe62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_training_data  = pd.read_csv('level4_training_vanilla.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33a2e768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7, 5), dpi = 400)\n",
    "# plt.plot(original_training_data[\"loss\"], label=\"Training data\")\n",
    "# plt.plot(original_training_data[\"val_loss\"], label=\"Validation data\")\n",
    "# plt.plot(history_df[\"loss\"], label=\"Shuffled training data\")\n",
    "# plt.plot(history_df[\"val_loss\"], label=\"Shuffled validation data\")\n",
    "# # plt.title(\"Loss for VAE training on Cell Painting Level 5 data\")\n",
    "# plt.ylabel(\"MSE + KL Divergence\")\n",
    "# plt.xlabel(\"No. Epoch\")\n",
    "# plt.ylim(0,5)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "759461ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "cp_vae = VAE(\n",
    "    input_dim=train_features_df.shape[1],\n",
    "    latent_dim=90,\n",
    "    batch_size=32,\n",
    "    encoder_batch_norm=True,\n",
    "    epochs=50,\n",
    "    learning_rate=0.0001,\n",
    "    encoder_architecture=encoder_architecture,\n",
    "    decoder_architecture=decoder_architecture,\n",
    "    beta=0,\n",
    "    lam = 10000,\n",
    "    verbose=True,\n",
    ")\n",
    "cp_vae.compile_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c3fb283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1258/1258 [==============================] - 10s 6ms/step - loss: 78.0448 - recon: 54.4351 - kl: 0.0000e+00 - mmd: 23.5357 - val_loss: 35.0460 - val_recon: 11.1319 - val_kl: 0.0000e+00 - val_mmd: 24.5580\n",
      "Epoch 2/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 25.3812 - recon: 7.2241 - kl: 0.0000e+00 - mmd: 18.1660 - val_loss: 24.9239 - val_recon: 5.2630 - val_kl: 0.0000e+00 - val_mmd: 20.2246\n",
      "Epoch 3/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 19.8233 - recon: 4.1960 - kl: 0.0000e+00 - mmd: 15.5104 - val_loss: 22.2547 - val_recon: 3.4452 - val_kl: 0.0000e+00 - val_mmd: 19.2425\n",
      "Epoch 4/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 17.1954 - recon: 2.8252 - kl: 0.0000e+00 - mmd: 14.3655 - val_loss: 18.1752 - val_recon: 2.3540 - val_kl: 0.0000e+00 - val_mmd: 15.9632\n",
      "Epoch 5/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 15.8905 - recon: 2.0554 - kl: 0.0000e+00 - mmd: 13.8377 - val_loss: 18.5727 - val_recon: 1.7786 - val_kl: 0.0000e+00 - val_mmd: 16.5313\n",
      "Epoch 6/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 15.1044 - recon: 1.6138 - kl: 0.0000e+00 - mmd: 13.5333 - val_loss: 17.3253 - val_recon: 1.4314 - val_kl: 0.0000e+00 - val_mmd: 16.1665\n",
      "Epoch 7/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 14.6328 - recon: 1.3624 - kl: 0.0000e+00 - mmd: 13.3302 - val_loss: 17.4369 - val_recon: 1.2401 - val_kl: 0.0000e+00 - val_mmd: 16.4538\n",
      "Epoch 8/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 14.4379 - recon: 1.2219 - kl: 0.0000e+00 - mmd: 13.2121 - val_loss: 16.5400 - val_recon: 1.1280 - val_kl: 0.0000e+00 - val_mmd: 16.3113\n",
      "Epoch 9/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 14.1336 - recon: 1.1405 - kl: 0.0000e+00 - mmd: 13.0196 - val_loss: 19.4539 - val_recon: 1.0681 - val_kl: 0.0000e+00 - val_mmd: 18.4368\n",
      "Epoch 10/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 14.0700 - recon: 1.0949 - kl: 0.0000e+00 - mmd: 12.8942 - val_loss: 16.7285 - val_recon: 1.0345 - val_kl: 0.0000e+00 - val_mmd: 16.1672\n",
      "Epoch 11/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 13.9013 - recon: 1.0707 - kl: 0.0000e+00 - mmd: 12.8322 - val_loss: 21.1673 - val_recon: 1.0169 - val_kl: 0.0000e+00 - val_mmd: 20.6434\n",
      "Epoch 12/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 13.6969 - recon: 1.0569 - kl: 0.0000e+00 - mmd: 12.6455 - val_loss: 19.2600 - val_recon: 1.0049 - val_kl: 0.0000e+00 - val_mmd: 18.6467\n",
      "Epoch 13/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 13.6449 - recon: 1.0494 - kl: 0.0000e+00 - mmd: 12.5565 - val_loss: 16.8944 - val_recon: 0.9991 - val_kl: 0.0000e+00 - val_mmd: 16.2366\n",
      "Epoch 14/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 13.5440 - recon: 1.0450 - kl: 0.0000e+00 - mmd: 12.4452 - val_loss: 19.1789 - val_recon: 0.9953 - val_kl: 0.0000e+00 - val_mmd: 18.2131\n",
      "Epoch 15/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 13.4378 - recon: 1.0422 - kl: 0.0000e+00 - mmd: 12.3872 - val_loss: 17.7216 - val_recon: 0.9925 - val_kl: 0.0000e+00 - val_mmd: 16.8465\n",
      "Epoch 16/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 13.3083 - recon: 1.0402 - kl: 0.0000e+00 - mmd: 12.2948 - val_loss: 16.5711 - val_recon: 0.9912 - val_kl: 0.0000e+00 - val_mmd: 15.6150\n",
      "Epoch 17/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 13.2208 - recon: 1.0390 - kl: 0.0000e+00 - mmd: 12.2654 - val_loss: 16.9297 - val_recon: 0.9907 - val_kl: 0.0000e+00 - val_mmd: 15.8423\n",
      "Epoch 18/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 13.2034 - recon: 1.0379 - kl: 0.0000e+00 - mmd: 12.2729 - val_loss: 15.9380 - val_recon: 0.9889 - val_kl: 0.0000e+00 - val_mmd: 15.2939\n",
      "Epoch 19/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 13.1632 - recon: 1.0370 - kl: 0.0000e+00 - mmd: 12.0299 - val_loss: 15.4552 - val_recon: 0.9887 - val_kl: 0.0000e+00 - val_mmd: 14.6401\n",
      "Epoch 20/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 13.0441 - recon: 1.0363 - kl: 0.0000e+00 - mmd: 11.9953 - val_loss: 15.8309 - val_recon: 0.9882 - val_kl: 0.0000e+00 - val_mmd: 15.3534\n",
      "Epoch 21/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 13.0096 - recon: 1.0354 - kl: 0.0000e+00 - mmd: 11.9777 - val_loss: 16.2019 - val_recon: 0.9875 - val_kl: 0.0000e+00 - val_mmd: 15.7165\n",
      "Epoch 22/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.9203 - recon: 1.0346 - kl: 0.0000e+00 - mmd: 11.8298 - val_loss: 15.4988 - val_recon: 0.9857 - val_kl: 0.0000e+00 - val_mmd: 14.7452\n",
      "Epoch 23/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.7605 - recon: 1.0340 - kl: 0.0000e+00 - mmd: 11.7942 - val_loss: 15.1430 - val_recon: 0.9855 - val_kl: 0.0000e+00 - val_mmd: 14.4717\n",
      "Epoch 24/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.7423 - recon: 1.0333 - kl: 0.0000e+00 - mmd: 11.6903 - val_loss: 16.1095 - val_recon: 0.9833 - val_kl: 0.0000e+00 - val_mmd: 15.2976\n",
      "Epoch 25/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.6883 - recon: 1.0326 - kl: 0.0000e+00 - mmd: 11.7158 - val_loss: 17.2665 - val_recon: 0.9846 - val_kl: 0.0000e+00 - val_mmd: 15.9414\n",
      "Epoch 26/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.5546 - recon: 1.0323 - kl: 0.0000e+00 - mmd: 11.5168 - val_loss: 15.7808 - val_recon: 0.9842 - val_kl: 0.0000e+00 - val_mmd: 15.1626\n",
      "Epoch 27/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.5068 - recon: 1.0316 - kl: 0.0000e+00 - mmd: 11.5615 - val_loss: 16.5563 - val_recon: 0.9838 - val_kl: 0.0000e+00 - val_mmd: 15.8551\n",
      "Epoch 28/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.5486 - recon: 1.0311 - kl: 0.0000e+00 - mmd: 11.4950 - val_loss: 15.5246 - val_recon: 0.9827 - val_kl: 0.0000e+00 - val_mmd: 14.7865\n",
      "Epoch 29/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.4294 - recon: 1.0303 - kl: 0.0000e+00 - mmd: 11.4218 - val_loss: 15.5874 - val_recon: 0.9833 - val_kl: 0.0000e+00 - val_mmd: 14.5076\n",
      "Epoch 30/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.2950 - recon: 1.0299 - kl: 0.0000e+00 - mmd: 11.2983 - val_loss: 14.4401 - val_recon: 0.9818 - val_kl: 0.0000e+00 - val_mmd: 13.3373\n",
      "Epoch 31/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.2424 - recon: 1.0293 - kl: 0.0000e+00 - mmd: 11.2655 - val_loss: 14.8657 - val_recon: 0.9808 - val_kl: 0.0000e+00 - val_mmd: 14.3105\n",
      "Epoch 32/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.2388 - recon: 1.0284 - kl: 0.0000e+00 - mmd: 11.2436 - val_loss: 18.4014 - val_recon: 0.9796 - val_kl: 0.0000e+00 - val_mmd: 17.8568\n",
      "Epoch 33/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.2136 - recon: 1.0278 - kl: 0.0000e+00 - mmd: 11.1831 - val_loss: 14.6314 - val_recon: 0.9799 - val_kl: 0.0000e+00 - val_mmd: 13.6556\n",
      "Epoch 34/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.1181 - recon: 1.0273 - kl: 0.0000e+00 - mmd: 11.1087 - val_loss: 16.3186 - val_recon: 0.9797 - val_kl: 0.0000e+00 - val_mmd: 15.6001\n",
      "Epoch 35/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.1468 - recon: 1.0269 - kl: 0.0000e+00 - mmd: 11.0884 - val_loss: 14.2119 - val_recon: 0.9775 - val_kl: 0.0000e+00 - val_mmd: 13.6520\n",
      "Epoch 36/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 12.0477 - recon: 1.0258 - kl: 0.0000e+00 - mmd: 10.9723 - val_loss: 14.6761 - val_recon: 0.9786 - val_kl: 0.0000e+00 - val_mmd: 13.9673\n",
      "Epoch 37/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.9634 - recon: 1.0255 - kl: 0.0000e+00 - mmd: 10.9709 - val_loss: 15.6472 - val_recon: 0.9780 - val_kl: 0.0000e+00 - val_mmd: 14.7049\n",
      "Epoch 38/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.9509 - recon: 1.0248 - kl: 0.0000e+00 - mmd: 10.9294 - val_loss: 14.4132 - val_recon: 0.9773 - val_kl: 0.0000e+00 - val_mmd: 13.4876\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.8520 - recon: 1.0242 - kl: 0.0000e+00 - mmd: 10.9194 - val_loss: 14.8790 - val_recon: 0.9754 - val_kl: 0.0000e+00 - val_mmd: 13.9525\n",
      "Epoch 40/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.8183 - recon: 1.0236 - kl: 0.0000e+00 - mmd: 10.8040 - val_loss: 14.3923 - val_recon: 0.9757 - val_kl: 0.0000e+00 - val_mmd: 13.6228\n",
      "Epoch 41/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.7689 - recon: 1.0227 - kl: 0.0000e+00 - mmd: 10.7524 - val_loss: 13.8829 - val_recon: 0.9760 - val_kl: 0.0000e+00 - val_mmd: 13.1357\n",
      "Epoch 42/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.6395 - recon: 1.0218 - kl: 0.0000e+00 - mmd: 10.6704 - val_loss: 14.2639 - val_recon: 0.9738 - val_kl: 0.0000e+00 - val_mmd: 13.3096\n",
      "Epoch 43/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.6389 - recon: 1.0211 - kl: 0.0000e+00 - mmd: 10.6509 - val_loss: 14.6947 - val_recon: 0.9735 - val_kl: 0.0000e+00 - val_mmd: 14.0562\n",
      "Epoch 44/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.6652 - recon: 1.0204 - kl: 0.0000e+00 - mmd: 10.6682 - val_loss: 14.2334 - val_recon: 0.9729 - val_kl: 0.0000e+00 - val_mmd: 13.5097\n",
      "Epoch 45/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.6009 - recon: 1.0192 - kl: 0.0000e+00 - mmd: 10.5182 - val_loss: 13.9945 - val_recon: 0.9730 - val_kl: 0.0000e+00 - val_mmd: 13.0266\n",
      "Epoch 46/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.5645 - recon: 1.0183 - kl: 0.0000e+00 - mmd: 10.4739 - val_loss: 13.8491 - val_recon: 0.9712 - val_kl: 0.0000e+00 - val_mmd: 12.8445\n",
      "Epoch 47/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.5702 - recon: 1.0170 - kl: 0.0000e+00 - mmd: 10.5111 - val_loss: 31.5945 - val_recon: 0.9711 - val_kl: 0.0000e+00 - val_mmd: 31.4197\n",
      "Epoch 48/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.5111 - recon: 1.0158 - kl: 0.0000e+00 - mmd: 10.4891 - val_loss: 13.8541 - val_recon: 0.9694 - val_kl: 0.0000e+00 - val_mmd: 12.8000\n",
      "Epoch 49/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.4902 - recon: 1.0148 - kl: 0.0000e+00 - mmd: 10.4073 - val_loss: 13.7935 - val_recon: 0.9662 - val_kl: 0.0000e+00 - val_mmd: 12.9336\n",
      "Epoch 50/50\n",
      "1258/1258 [==============================] - 8s 6ms/step - loss: 11.3920 - recon: 1.0130 - kl: 0.0000e+00 - mmd: 10.3762 - val_loss: 13.8423 - val_recon: 0.9654 - val_kl: 0.0000e+00 - val_mmd: 12.9154\n"
     ]
    }
   ],
   "source": [
    "cp_vae.train(x_train=train_features_df, x_test=valid_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dd06c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fa6a4361810>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_vae.vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51e3b23a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recon</th>\n",
       "      <th>kl</th>\n",
       "      <th>mmd</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recon</th>\n",
       "      <th>val_kl</th>\n",
       "      <th>val_mmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.044777</td>\n",
       "      <td>54.435055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.535709</td>\n",
       "      <td>35.046013</td>\n",
       "      <td>11.131903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.557991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.381241</td>\n",
       "      <td>7.224068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.166002</td>\n",
       "      <td>24.923874</td>\n",
       "      <td>5.262980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.224573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.823282</td>\n",
       "      <td>4.196005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.510356</td>\n",
       "      <td>22.254669</td>\n",
       "      <td>3.445248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.242504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.195419</td>\n",
       "      <td>2.825225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.365484</td>\n",
       "      <td>18.175192</td>\n",
       "      <td>2.354046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.963177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.890542</td>\n",
       "      <td>2.055385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.837684</td>\n",
       "      <td>18.572666</td>\n",
       "      <td>1.778565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.531254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.104353</td>\n",
       "      <td>1.613759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.533289</td>\n",
       "      <td>17.325323</td>\n",
       "      <td>1.431351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.166536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.632801</td>\n",
       "      <td>1.362445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.330157</td>\n",
       "      <td>17.436863</td>\n",
       "      <td>1.240074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.453779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.437928</td>\n",
       "      <td>1.221852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.212083</td>\n",
       "      <td>16.539963</td>\n",
       "      <td>1.127990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.311323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.133565</td>\n",
       "      <td>1.140476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.019581</td>\n",
       "      <td>19.453928</td>\n",
       "      <td>1.068129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.436792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.070037</td>\n",
       "      <td>1.094904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.894222</td>\n",
       "      <td>16.728477</td>\n",
       "      <td>1.034456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.167183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.901271</td>\n",
       "      <td>1.070725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.832209</td>\n",
       "      <td>21.167276</td>\n",
       "      <td>1.016919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.643421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.696937</td>\n",
       "      <td>1.056888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.645452</td>\n",
       "      <td>19.260019</td>\n",
       "      <td>1.004897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.644878</td>\n",
       "      <td>1.049357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.556504</td>\n",
       "      <td>16.894430</td>\n",
       "      <td>0.999150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.236565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.543965</td>\n",
       "      <td>1.044982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.445186</td>\n",
       "      <td>19.178947</td>\n",
       "      <td>0.995346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.213133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.437769</td>\n",
       "      <td>1.042238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.387248</td>\n",
       "      <td>17.721601</td>\n",
       "      <td>0.992501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.846472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.308292</td>\n",
       "      <td>1.040225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.294792</td>\n",
       "      <td>16.571079</td>\n",
       "      <td>0.991180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.615020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.220816</td>\n",
       "      <td>1.039048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.265445</td>\n",
       "      <td>16.929651</td>\n",
       "      <td>0.990721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.842312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.203399</td>\n",
       "      <td>1.037910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.272889</td>\n",
       "      <td>15.937963</td>\n",
       "      <td>0.988944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.293923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13.163222</td>\n",
       "      <td>1.036980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.029904</td>\n",
       "      <td>15.455181</td>\n",
       "      <td>0.988741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.640121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.044054</td>\n",
       "      <td>1.036292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.995253</td>\n",
       "      <td>15.830930</td>\n",
       "      <td>0.988182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.353433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.009636</td>\n",
       "      <td>1.035444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.977738</td>\n",
       "      <td>16.201931</td>\n",
       "      <td>0.987493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.716486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.920326</td>\n",
       "      <td>1.034610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.829815</td>\n",
       "      <td>15.498836</td>\n",
       "      <td>0.985675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.745162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.760543</td>\n",
       "      <td>1.033977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.794240</td>\n",
       "      <td>15.142990</td>\n",
       "      <td>0.985463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.471704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.742269</td>\n",
       "      <td>1.033256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.690312</td>\n",
       "      <td>16.109461</td>\n",
       "      <td>0.983335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.297617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.688323</td>\n",
       "      <td>1.032551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.715797</td>\n",
       "      <td>17.266464</td>\n",
       "      <td>0.984561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.941396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.554556</td>\n",
       "      <td>1.032269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.516846</td>\n",
       "      <td>15.780766</td>\n",
       "      <td>0.984184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.162559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.506824</td>\n",
       "      <td>1.031577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.561499</td>\n",
       "      <td>16.556347</td>\n",
       "      <td>0.983771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.855072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.548621</td>\n",
       "      <td>1.031098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.494995</td>\n",
       "      <td>15.524607</td>\n",
       "      <td>0.982664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.786451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12.429431</td>\n",
       "      <td>1.030254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.421789</td>\n",
       "      <td>15.587351</td>\n",
       "      <td>0.983288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.507646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.294978</td>\n",
       "      <td>1.029853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.298306</td>\n",
       "      <td>14.440073</td>\n",
       "      <td>0.981788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.337297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12.242401</td>\n",
       "      <td>1.029263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.265512</td>\n",
       "      <td>14.865685</td>\n",
       "      <td>0.980829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.310465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.238791</td>\n",
       "      <td>1.028445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.243579</td>\n",
       "      <td>18.401388</td>\n",
       "      <td>0.979627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.856850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.213584</td>\n",
       "      <td>1.027827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.183084</td>\n",
       "      <td>14.631359</td>\n",
       "      <td>0.979925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.655647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.118089</td>\n",
       "      <td>1.027328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.108718</td>\n",
       "      <td>16.318609</td>\n",
       "      <td>0.979730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.600120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12.146803</td>\n",
       "      <td>1.026915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.088433</td>\n",
       "      <td>14.211926</td>\n",
       "      <td>0.977451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.652020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12.047688</td>\n",
       "      <td>1.025773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.972282</td>\n",
       "      <td>14.676080</td>\n",
       "      <td>0.978570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.967320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>11.963396</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.970909</td>\n",
       "      <td>15.647242</td>\n",
       "      <td>0.977994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.704902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>11.950936</td>\n",
       "      <td>1.024809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.929408</td>\n",
       "      <td>14.413204</td>\n",
       "      <td>0.977311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.487632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>11.852029</td>\n",
       "      <td>1.024187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.919382</td>\n",
       "      <td>14.879033</td>\n",
       "      <td>0.975394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.952518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>11.818270</td>\n",
       "      <td>1.023621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.804009</td>\n",
       "      <td>14.392336</td>\n",
       "      <td>0.975719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.622790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>11.768888</td>\n",
       "      <td>1.022706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.752419</td>\n",
       "      <td>13.882876</td>\n",
       "      <td>0.976009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.135673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>11.639545</td>\n",
       "      <td>1.021794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.670387</td>\n",
       "      <td>14.263947</td>\n",
       "      <td>0.973849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.309618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>11.638872</td>\n",
       "      <td>1.021062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.650860</td>\n",
       "      <td>14.694682</td>\n",
       "      <td>0.973517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.056230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>11.665200</td>\n",
       "      <td>1.020410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.668246</td>\n",
       "      <td>14.233359</td>\n",
       "      <td>0.972864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.509679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11.600864</td>\n",
       "      <td>1.019241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.518247</td>\n",
       "      <td>13.994474</td>\n",
       "      <td>0.973029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.026581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>11.564486</td>\n",
       "      <td>1.018346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.473944</td>\n",
       "      <td>13.849123</td>\n",
       "      <td>0.971231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.844493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>11.570215</td>\n",
       "      <td>1.017026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.511135</td>\n",
       "      <td>31.594501</td>\n",
       "      <td>0.971130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.419727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>11.511108</td>\n",
       "      <td>1.015809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.489087</td>\n",
       "      <td>13.854140</td>\n",
       "      <td>0.969381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.800027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>11.490197</td>\n",
       "      <td>1.014750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.407297</td>\n",
       "      <td>13.793471</td>\n",
       "      <td>0.966153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.933601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>11.391993</td>\n",
       "      <td>1.012994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.376182</td>\n",
       "      <td>13.842267</td>\n",
       "      <td>0.965435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.915386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss      recon   kl        mmd   val_loss  val_recon  val_kl  \\\n",
       "0   78.044777  54.435055  0.0  23.535709  35.046013  11.131903     0.0   \n",
       "1   25.381241   7.224068  0.0  18.166002  24.923874   5.262980     0.0   \n",
       "2   19.823282   4.196005  0.0  15.510356  22.254669   3.445248     0.0   \n",
       "3   17.195419   2.825225  0.0  14.365484  18.175192   2.354046     0.0   \n",
       "4   15.890542   2.055385  0.0  13.837684  18.572666   1.778565     0.0   \n",
       "5   15.104353   1.613759  0.0  13.533289  17.325323   1.431351     0.0   \n",
       "6   14.632801   1.362445  0.0  13.330157  17.436863   1.240074     0.0   \n",
       "7   14.437928   1.221852  0.0  13.212083  16.539963   1.127990     0.0   \n",
       "8   14.133565   1.140476  0.0  13.019581  19.453928   1.068129     0.0   \n",
       "9   14.070037   1.094904  0.0  12.894222  16.728477   1.034456     0.0   \n",
       "10  13.901271   1.070725  0.0  12.832209  21.167276   1.016919     0.0   \n",
       "11  13.696937   1.056888  0.0  12.645452  19.260019   1.004897     0.0   \n",
       "12  13.644878   1.049357  0.0  12.556504  16.894430   0.999150     0.0   \n",
       "13  13.543965   1.044982  0.0  12.445186  19.178947   0.995346     0.0   \n",
       "14  13.437769   1.042238  0.0  12.387248  17.721601   0.992501     0.0   \n",
       "15  13.308292   1.040225  0.0  12.294792  16.571079   0.991180     0.0   \n",
       "16  13.220816   1.039048  0.0  12.265445  16.929651   0.990721     0.0   \n",
       "17  13.203399   1.037910  0.0  12.272889  15.937963   0.988944     0.0   \n",
       "18  13.163222   1.036980  0.0  12.029904  15.455181   0.988741     0.0   \n",
       "19  13.044054   1.036292  0.0  11.995253  15.830930   0.988182     0.0   \n",
       "20  13.009636   1.035444  0.0  11.977738  16.201931   0.987493     0.0   \n",
       "21  12.920326   1.034610  0.0  11.829815  15.498836   0.985675     0.0   \n",
       "22  12.760543   1.033977  0.0  11.794240  15.142990   0.985463     0.0   \n",
       "23  12.742269   1.033256  0.0  11.690312  16.109461   0.983335     0.0   \n",
       "24  12.688323   1.032551  0.0  11.715797  17.266464   0.984561     0.0   \n",
       "25  12.554556   1.032269  0.0  11.516846  15.780766   0.984184     0.0   \n",
       "26  12.506824   1.031577  0.0  11.561499  16.556347   0.983771     0.0   \n",
       "27  12.548621   1.031098  0.0  11.494995  15.524607   0.982664     0.0   \n",
       "28  12.429431   1.030254  0.0  11.421789  15.587351   0.983288     0.0   \n",
       "29  12.294978   1.029853  0.0  11.298306  14.440073   0.981788     0.0   \n",
       "30  12.242401   1.029263  0.0  11.265512  14.865685   0.980829     0.0   \n",
       "31  12.238791   1.028445  0.0  11.243579  18.401388   0.979627     0.0   \n",
       "32  12.213584   1.027827  0.0  11.183084  14.631359   0.979925     0.0   \n",
       "33  12.118089   1.027328  0.0  11.108718  16.318609   0.979730     0.0   \n",
       "34  12.146803   1.026915  0.0  11.088433  14.211926   0.977451     0.0   \n",
       "35  12.047688   1.025773  0.0  10.972282  14.676080   0.978570     0.0   \n",
       "36  11.963396   1.025476  0.0  10.970909  15.647242   0.977994     0.0   \n",
       "37  11.950936   1.024809  0.0  10.929408  14.413204   0.977311     0.0   \n",
       "38  11.852029   1.024187  0.0  10.919382  14.879033   0.975394     0.0   \n",
       "39  11.818270   1.023621  0.0  10.804009  14.392336   0.975719     0.0   \n",
       "40  11.768888   1.022706  0.0  10.752419  13.882876   0.976009     0.0   \n",
       "41  11.639545   1.021794  0.0  10.670387  14.263947   0.973849     0.0   \n",
       "42  11.638872   1.021062  0.0  10.650860  14.694682   0.973517     0.0   \n",
       "43  11.665200   1.020410  0.0  10.668246  14.233359   0.972864     0.0   \n",
       "44  11.600864   1.019241  0.0  10.518247  13.994474   0.973029     0.0   \n",
       "45  11.564486   1.018346  0.0  10.473944  13.849123   0.971231     0.0   \n",
       "46  11.570215   1.017026  0.0  10.511135  31.594501   0.971130     0.0   \n",
       "47  11.511108   1.015809  0.0  10.489087  13.854140   0.969381     0.0   \n",
       "48  11.490197   1.014750  0.0  10.407297  13.793471   0.966153     0.0   \n",
       "49  11.391993   1.012994  0.0  10.376182  13.842267   0.965435     0.0   \n",
       "\n",
       "      val_mmd  \n",
       "0   24.557991  \n",
       "1   20.224573  \n",
       "2   19.242504  \n",
       "3   15.963177  \n",
       "4   16.531254  \n",
       "5   16.166536  \n",
       "6   16.453779  \n",
       "7   16.311323  \n",
       "8   18.436792  \n",
       "9   16.167183  \n",
       "10  20.643421  \n",
       "11  18.646727  \n",
       "12  16.236565  \n",
       "13  18.213133  \n",
       "14  16.846472  \n",
       "15  15.615020  \n",
       "16  15.842312  \n",
       "17  15.293923  \n",
       "18  14.640121  \n",
       "19  15.353433  \n",
       "20  15.716486  \n",
       "21  14.745162  \n",
       "22  14.471704  \n",
       "23  15.297617  \n",
       "24  15.941396  \n",
       "25  15.162559  \n",
       "26  15.855072  \n",
       "27  14.786451  \n",
       "28  14.507646  \n",
       "29  13.337297  \n",
       "30  14.310465  \n",
       "31  17.856850  \n",
       "32  13.655647  \n",
       "33  15.600120  \n",
       "34  13.652020  \n",
       "35  13.967320  \n",
       "36  14.704902  \n",
       "37  13.487632  \n",
       "38  13.952518  \n",
       "39  13.622790  \n",
       "40  13.135673  \n",
       "41  13.309618  \n",
       "42  14.056230  \n",
       "43  13.509679  \n",
       "44  13.026581  \n",
       "45  12.844493  \n",
       "46  31.419727  \n",
       "47  12.800027  \n",
       "48  12.933601  \n",
       "49  12.915386  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save training performance\n",
    "history_df = pd.DataFrame(cp_vae.vae.history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02b846ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/level4EncoderShuffled_mmd/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/level4DecoderShuffled_mmd/assets\n"
     ]
    }
   ],
   "source": [
    "encoder = cp_vae.encoder_block[\"encoder\"]\n",
    "decoder = cp_vae.decoder_block[\"decoder\"]\n",
    "encoder.save(\"models/level4EncoderShuffled_mmd\")\n",
    "decoder.save(\"models/level4DecoderShuffled_mmd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c23b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_df.to_csv('level4_training_mmd_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b54be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_training_data  = pd.read_csv('level4_training_mmd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b3608be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7, 5), dpi = 400)\n",
    "# plt.plot(original_training_data[\"loss\"], label=\"Training data\")\n",
    "# plt.plot(original_training_data[\"val_loss\"], label=\"Validation data\")\n",
    "# plt.plot(history_df[\"loss\"], label=\"Shuffled training data\")\n",
    "# plt.plot(history_df[\"val_loss\"], label=\"Shuffled validation data\")\n",
    "# # plt.title(\"Loss for VAE training on Cell Painting Level 5 data\")\n",
    "# plt.ylabel(\"MSE + MMD\")\n",
    "# plt.xlabel(\"No. Epoch\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864dc53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
