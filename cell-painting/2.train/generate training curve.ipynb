{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06345df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.insert(0, \"../../scripts\")\n",
    "from utils import load_data\n",
    "\n",
    "\n",
    "from pycytominer.cyto_utils import infer_cp_features\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow import keras\n",
    "\n",
    "from vae import VAE\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import seaborn\n",
    "import random as python_random\n",
    "import tensorflow as tf\n",
    "# import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c62b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c4f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = [\"train\", \"test\", \"valid\", \"complete\"]\n",
    "data_dict = load_data(data_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16715d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "meta_features = infer_cp_features(data_dict[\"train\"], metadata=True)\n",
    "cp_features = infer_cp_features(data_dict[\"train\"])\n",
    "\n",
    "train_features_df = data_dict[\"train\"].reindex(cp_features, axis=\"columns\")\n",
    "train_meta_df = data_dict[\"train\"].reindex(meta_features, axis=\"columns\")\n",
    "\n",
    "test_features_df = data_dict[\"test\"].reindex(cp_features, axis=\"columns\")\n",
    "test_meta_df = data_dict[\"test\"].reindex(meta_features, axis=\"columns\")\n",
    "\n",
    "valid_features_df = data_dict[\"valid\"].reindex(cp_features, axis=\"columns\")\n",
    "valid_meta_df = data_dict[\"valid\"].reindex(meta_features, axis=\"columns\")\n",
    "\n",
    "complete_features_df = data_dict[\"complete\"].reindex(cp_features, axis=\"columns\")\n",
    "complete_meta_df = data_dict[\"complete\"].reindex(meta_features, axis=\"columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc7c541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8294, 588)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cells_AreaShape_FormFactor</th>\n",
       "      <th>Cells_AreaShape_Orientation</th>\n",
       "      <th>Cells_AreaShape_Zernike_2_2</th>\n",
       "      <th>Cells_AreaShape_Zernike_3_1</th>\n",
       "      <th>Cells_AreaShape_Zernike_5_1</th>\n",
       "      <th>Cells_AreaShape_Zernike_6_2</th>\n",
       "      <th>Cells_AreaShape_Zernike_7_1</th>\n",
       "      <th>Cells_AreaShape_Zernike_7_7</th>\n",
       "      <th>Cells_AreaShape_Zernike_9_3</th>\n",
       "      <th>Cells_Correlation_Correlation_DNA_AGP</th>\n",
       "      <th>...</th>\n",
       "      <th>Nuclei_Texture_SumAverage_AGP_5_0</th>\n",
       "      <th>Nuclei_Texture_SumEntropy_AGP_10_0</th>\n",
       "      <th>Nuclei_Texture_SumEntropy_AGP_20_0</th>\n",
       "      <th>Nuclei_Texture_SumEntropy_AGP_5_0</th>\n",
       "      <th>Nuclei_Texture_SumEntropy_DNA_10_0</th>\n",
       "      <th>Nuclei_Texture_SumEntropy_DNA_20_0</th>\n",
       "      <th>Nuclei_Texture_SumEntropy_Mito_5_0</th>\n",
       "      <th>Nuclei_Texture_SumVariance_DNA_5_0</th>\n",
       "      <th>Nuclei_Texture_Variance_DNA_20_0</th>\n",
       "      <th>Nuclei_Texture_Variance_DNA_5_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.56071</td>\n",
       "      <td>0.63708</td>\n",
       "      <td>0.57961</td>\n",
       "      <td>0.51030</td>\n",
       "      <td>0.61695</td>\n",
       "      <td>0.30869</td>\n",
       "      <td>0.43981</td>\n",
       "      <td>0.79826</td>\n",
       "      <td>0.72477</td>\n",
       "      <td>0.68589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17858</td>\n",
       "      <td>0.29336</td>\n",
       "      <td>0.26447</td>\n",
       "      <td>0.30197</td>\n",
       "      <td>0.64786</td>\n",
       "      <td>0.49525</td>\n",
       "      <td>0.53512</td>\n",
       "      <td>0.40495</td>\n",
       "      <td>0.46056</td>\n",
       "      <td>0.43647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.59702</td>\n",
       "      <td>0.55453</td>\n",
       "      <td>0.62561</td>\n",
       "      <td>0.47959</td>\n",
       "      <td>0.59022</td>\n",
       "      <td>0.33269</td>\n",
       "      <td>0.49875</td>\n",
       "      <td>0.88042</td>\n",
       "      <td>0.67159</td>\n",
       "      <td>0.61703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09030</td>\n",
       "      <td>0.15088</td>\n",
       "      <td>0.13334</td>\n",
       "      <td>0.14052</td>\n",
       "      <td>0.59229</td>\n",
       "      <td>0.49294</td>\n",
       "      <td>0.43221</td>\n",
       "      <td>0.33969</td>\n",
       "      <td>0.39208</td>\n",
       "      <td>0.36205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.64623</td>\n",
       "      <td>0.59825</td>\n",
       "      <td>0.62822</td>\n",
       "      <td>0.52100</td>\n",
       "      <td>0.57452</td>\n",
       "      <td>0.26367</td>\n",
       "      <td>0.48172</td>\n",
       "      <td>0.86322</td>\n",
       "      <td>0.67588</td>\n",
       "      <td>0.69732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18125</td>\n",
       "      <td>0.23244</td>\n",
       "      <td>0.20723</td>\n",
       "      <td>0.24062</td>\n",
       "      <td>0.54642</td>\n",
       "      <td>0.43920</td>\n",
       "      <td>0.41183</td>\n",
       "      <td>0.30375</td>\n",
       "      <td>0.35385</td>\n",
       "      <td>0.33266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 588 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cells_AreaShape_FormFactor  Cells_AreaShape_Orientation  \\\n",
       "0                     0.56071                      0.63708   \n",
       "1                     0.59702                      0.55453   \n",
       "2                     0.64623                      0.59825   \n",
       "\n",
       "   Cells_AreaShape_Zernike_2_2  Cells_AreaShape_Zernike_3_1  \\\n",
       "0                      0.57961                      0.51030   \n",
       "1                      0.62561                      0.47959   \n",
       "2                      0.62822                      0.52100   \n",
       "\n",
       "   Cells_AreaShape_Zernike_5_1  Cells_AreaShape_Zernike_6_2  \\\n",
       "0                      0.61695                      0.30869   \n",
       "1                      0.59022                      0.33269   \n",
       "2                      0.57452                      0.26367   \n",
       "\n",
       "   Cells_AreaShape_Zernike_7_1  Cells_AreaShape_Zernike_7_7  \\\n",
       "0                      0.43981                      0.79826   \n",
       "1                      0.49875                      0.88042   \n",
       "2                      0.48172                      0.86322   \n",
       "\n",
       "   Cells_AreaShape_Zernike_9_3  Cells_Correlation_Correlation_DNA_AGP  ...  \\\n",
       "0                      0.72477                                0.68589  ...   \n",
       "1                      0.67159                                0.61703  ...   \n",
       "2                      0.67588                                0.69732  ...   \n",
       "\n",
       "   Nuclei_Texture_SumAverage_AGP_5_0  Nuclei_Texture_SumEntropy_AGP_10_0  \\\n",
       "0                            0.17858                             0.29336   \n",
       "1                            0.09030                             0.15088   \n",
       "2                            0.18125                             0.23244   \n",
       "\n",
       "   Nuclei_Texture_SumEntropy_AGP_20_0  Nuclei_Texture_SumEntropy_AGP_5_0  \\\n",
       "0                             0.26447                            0.30197   \n",
       "1                             0.13334                            0.14052   \n",
       "2                             0.20723                            0.24062   \n",
       "\n",
       "   Nuclei_Texture_SumEntropy_DNA_10_0  Nuclei_Texture_SumEntropy_DNA_20_0  \\\n",
       "0                             0.64786                             0.49525   \n",
       "1                             0.59229                             0.49294   \n",
       "2                             0.54642                             0.43920   \n",
       "\n",
       "   Nuclei_Texture_SumEntropy_Mito_5_0  Nuclei_Texture_SumVariance_DNA_5_0  \\\n",
       "0                             0.53512                             0.40495   \n",
       "1                             0.43221                             0.33969   \n",
       "2                             0.41183                             0.30375   \n",
       "\n",
       "   Nuclei_Texture_Variance_DNA_20_0  Nuclei_Texture_Variance_DNA_5_0  \n",
       "0                           0.46056                          0.43647  \n",
       "1                           0.39208                          0.36205  \n",
       "2                           0.35385                          0.33266  \n",
       "\n",
       "[3 rows x 588 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_features_df.shape)\n",
    "train_features_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef12cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_each_column(df):\n",
    "    columns = df.columns\n",
    "    df_copy = df.copy()\n",
    "    for column in columns:\n",
    "        df_copy[column] = df_copy[column].sample(frac=1).reset_index(drop=True)\n",
    "    return (df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dcb43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_df = shuffle_each_column(train_features_df)\n",
    "valid_features_df = shuffle_each_column(valid_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab060de",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_architecture=[250]\n",
    "decoder_architecture=[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "041e618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 01:44:28.944703: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-14 01:44:28.944743: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-14 01:44:28.944771: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-3-81): /proc/driver/nvidia/version does not exist\n",
      "2022-01-14 01:44:28.945046: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "cp_vae = VAE(\n",
    "    input_dim=train_features_df.shape[1],\n",
    "    latent_dim=10,\n",
    "    batch_size=96,\n",
    "    encoder_batch_norm=True,\n",
    "    epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    encoder_architecture=encoder_architecture,\n",
    "    decoder_architecture=decoder_architecture,\n",
    "    beta=.3,\n",
    "    verbose=True,\n",
    ")\n",
    "cp_vae.compile_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d01b91a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 01:44:30.529914: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "87/87 [==============================] - 4s 13ms/step - loss: 33.4196 - recon: 32.0597 - kl: 1.3599 - mmd: 0.0000e+00 - val_loss: 11.5276 - val_recon: 10.6055 - val_kl: 0.9221 - val_mmd: 0.0000e+00\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.5415 - recon: 10.3365 - kl: 1.2050 - mmd: 0.0000e+00 - val_loss: 10.7611 - val_recon: 9.4479 - val_kl: 1.3132 - val_mmd: 0.0000e+00\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.9388 - recon: 7.8849 - kl: 1.0539 - mmd: 0.0000e+00 - val_loss: 14.3468 - val_recon: 11.6339 - val_kl: 2.7128 - val_mmd: 0.0000e+00\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 7.4698 - recon: 6.5535 - kl: 0.9164 - mmd: 0.0000e+00 - val_loss: 8.1009 - val_recon: 6.6402 - val_kl: 1.4607 - val_mmd: 0.0000e+00\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 6.6829 - recon: 5.8854 - kl: 0.7975 - mmd: 0.0000e+00 - val_loss: 7.1492 - val_recon: 5.8976 - val_kl: 1.2516 - val_mmd: 0.0000e+00\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 6.3000 - recon: 5.6015 - kl: 0.6984 - mmd: 0.0000e+00 - val_loss: 6.5414 - val_recon: 5.5619 - val_kl: 0.9794 - val_mmd: 0.0000e+00\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 6.0817 - recon: 5.4679 - kl: 0.6138 - mmd: 0.0000e+00 - val_loss: 6.1829 - val_recon: 5.3825 - val_kl: 0.8004 - val_mmd: 0.0000e+00\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.9522 - recon: 5.4111 - kl: 0.5411 - mmd: 0.0000e+00 - val_loss: 6.0203 - val_recon: 5.3131 - val_kl: 0.7072 - val_mmd: 0.0000e+00\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.8581 - recon: 5.3809 - kl: 0.4771 - mmd: 0.0000e+00 - val_loss: 5.8433 - val_recon: 5.2719 - val_kl: 0.5714 - val_mmd: 0.0000e+00\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.7825 - recon: 5.3609 - kl: 0.4217 - mmd: 0.0000e+00 - val_loss: 5.7466 - val_recon: 5.2518 - val_kl: 0.4948 - val_mmd: 0.0000e+00\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.7243 - recon: 5.3504 - kl: 0.3739 - mmd: 0.0000e+00 - val_loss: 5.6535 - val_recon: 5.2390 - val_kl: 0.4145 - val_mmd: 0.0000e+00\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.6759 - recon: 5.3435 - kl: 0.3324 - mmd: 0.0000e+00 - val_loss: 5.6034 - val_recon: 5.2228 - val_kl: 0.3805 - val_mmd: 0.0000e+00\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.6337 - recon: 5.3380 - kl: 0.2956 - mmd: 0.0000e+00 - val_loss: 5.5491 - val_recon: 5.2186 - val_kl: 0.3305 - val_mmd: 0.0000e+00\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.6005 - recon: 5.3357 - kl: 0.2648 - mmd: 0.0000e+00 - val_loss: 5.5240 - val_recon: 5.2190 - val_kl: 0.3049 - val_mmd: 0.0000e+00\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.5700 - recon: 5.3319 - kl: 0.2381 - mmd: 0.0000e+00 - val_loss: 5.4839 - val_recon: 5.2166 - val_kl: 0.2674 - val_mmd: 0.0000e+00\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.5426 - recon: 5.3280 - kl: 0.2146 - mmd: 0.0000e+00 - val_loss: 5.4627 - val_recon: 5.2181 - val_kl: 0.2446 - val_mmd: 0.0000e+00\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.5221 - recon: 5.3272 - kl: 0.1949 - mmd: 0.0000e+00 - val_loss: 5.4288 - val_recon: 5.2107 - val_kl: 0.2181 - val_mmd: 0.0000e+00\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.5049 - recon: 5.3277 - kl: 0.1772 - mmd: 0.0000e+00 - val_loss: 5.4005 - val_recon: 5.2077 - val_kl: 0.1929 - val_mmd: 0.0000e+00\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4870 - recon: 5.3252 - kl: 0.1618 - mmd: 0.0000e+00 - val_loss: 5.3882 - val_recon: 5.2030 - val_kl: 0.1851 - val_mmd: 0.0000e+00\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4721 - recon: 5.3237 - kl: 0.1484 - mmd: 0.0000e+00 - val_loss: 5.3751 - val_recon: 5.2106 - val_kl: 0.1645 - val_mmd: 0.0000e+00\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4583 - recon: 5.3218 - kl: 0.1364 - mmd: 0.0000e+00 - val_loss: 5.3580 - val_recon: 5.2041 - val_kl: 0.1539 - val_mmd: 0.0000e+00\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4491 - recon: 5.3230 - kl: 0.1261 - mmd: 0.0000e+00 - val_loss: 5.3466 - val_recon: 5.2027 - val_kl: 0.1439 - val_mmd: 0.0000e+00\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4384 - recon: 5.3215 - kl: 0.1168 - mmd: 0.0000e+00 - val_loss: 5.3393 - val_recon: 5.2042 - val_kl: 0.1351 - val_mmd: 0.0000e+00\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4292 - recon: 5.3206 - kl: 0.1085 - mmd: 0.0000e+00 - val_loss: 5.3268 - val_recon: 5.2009 - val_kl: 0.1260 - val_mmd: 0.0000e+00\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4211 - recon: 5.3200 - kl: 0.1011 - mmd: 0.0000e+00 - val_loss: 5.3173 - val_recon: 5.2013 - val_kl: 0.1160 - val_mmd: 0.0000e+00\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4133 - recon: 5.3191 - kl: 0.0942 - mmd: 0.0000e+00 - val_loss: 5.3127 - val_recon: 5.2031 - val_kl: 0.1096 - val_mmd: 0.0000e+00\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4070 - recon: 5.3187 - kl: 0.0883 - mmd: 0.0000e+00 - val_loss: 5.3024 - val_recon: 5.2002 - val_kl: 0.1021 - val_mmd: 0.0000e+00\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3994 - recon: 5.3166 - kl: 0.0828 - mmd: 0.0000e+00 - val_loss: 5.2963 - val_recon: 5.2004 - val_kl: 0.0959 - val_mmd: 0.0000e+00\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3939 - recon: 5.3163 - kl: 0.0777 - mmd: 0.0000e+00 - val_loss: 5.2916 - val_recon: 5.2011 - val_kl: 0.0905 - val_mmd: 0.0000e+00\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3898 - recon: 5.3165 - kl: 0.0732 - mmd: 0.0000e+00 - val_loss: 5.2907 - val_recon: 5.2048 - val_kl: 0.0859 - val_mmd: 0.0000e+00\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3842 - recon: 5.3152 - kl: 0.0690 - mmd: 0.0000e+00 - val_loss: 5.2749 - val_recon: 5.1941 - val_kl: 0.0808 - val_mmd: 0.0000e+00\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3781 - recon: 5.3131 - kl: 0.0650 - mmd: 0.0000e+00 - val_loss: 5.2705 - val_recon: 5.1943 - val_kl: 0.0762 - val_mmd: 0.0000e+00\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3757 - recon: 5.3142 - kl: 0.0614 - mmd: 0.0000e+00 - val_loss: 5.2679 - val_recon: 5.1961 - val_kl: 0.0717 - val_mmd: 0.0000e+00\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3704 - recon: 5.3123 - kl: 0.0581 - mmd: 0.0000e+00 - val_loss: 5.2649 - val_recon: 5.1967 - val_kl: 0.0683 - val_mmd: 0.0000e+00\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3669 - recon: 5.3118 - kl: 0.0551 - mmd: 0.0000e+00 - val_loss: 5.2585 - val_recon: 5.1937 - val_kl: 0.0648 - val_mmd: 0.0000e+00\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3648 - recon: 5.3125 - kl: 0.0524 - mmd: 0.0000e+00 - val_loss: 5.2531 - val_recon: 5.1916 - val_kl: 0.0615 - val_mmd: 0.0000e+00\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3606 - recon: 5.3109 - kl: 0.0497 - mmd: 0.0000e+00 - val_loss: 5.2466 - val_recon: 5.1884 - val_kl: 0.0582 - val_mmd: 0.0000e+00\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3557 - recon: 5.3085 - kl: 0.0472 - mmd: 0.0000e+00 - val_loss: 5.2436 - val_recon: 5.1884 - val_kl: 0.0553 - val_mmd: 0.0000e+00\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3541 - recon: 5.3092 - kl: 0.0449 - mmd: 0.0000e+00 - val_loss: 5.2430 - val_recon: 5.1902 - val_kl: 0.0527 - val_mmd: 0.0000e+00\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3509 - recon: 5.3081 - kl: 0.0429 - mmd: 0.0000e+00 - val_loss: 5.2386 - val_recon: 5.1887 - val_kl: 0.0498 - val_mmd: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3488 - recon: 5.3079 - kl: 0.0409 - mmd: 0.0000e+00 - val_loss: 5.2363 - val_recon: 5.1888 - val_kl: 0.0475 - val_mmd: 0.0000e+00\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3451 - recon: 5.3061 - kl: 0.0390 - mmd: 0.0000e+00 - val_loss: 5.2301 - val_recon: 5.1846 - val_kl: 0.0455 - val_mmd: 0.0000e+00\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3447 - recon: 5.3074 - kl: 0.0373 - mmd: 0.0000e+00 - val_loss: 5.2279 - val_recon: 5.1845 - val_kl: 0.0434 - val_mmd: 0.0000e+00\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3421 - recon: 5.3065 - kl: 0.0356 - mmd: 0.0000e+00 - val_loss: 5.2240 - val_recon: 5.1825 - val_kl: 0.0415 - val_mmd: 0.0000e+00\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3393 - recon: 5.3052 - kl: 0.0341 - mmd: 0.0000e+00 - val_loss: 5.2185 - val_recon: 5.1791 - val_kl: 0.0394 - val_mmd: 0.0000e+00\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3376 - recon: 5.3050 - kl: 0.0326 - mmd: 0.0000e+00 - val_loss: 5.2222 - val_recon: 5.1846 - val_kl: 0.0376 - val_mmd: 0.0000e+00\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3358 - recon: 5.3045 - kl: 0.0313 - mmd: 0.0000e+00 - val_loss: 5.2201 - val_recon: 5.1839 - val_kl: 0.0362 - val_mmd: 0.0000e+00\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3322 - recon: 5.3023 - kl: 0.0299 - mmd: 0.0000e+00 - val_loss: 5.2215 - val_recon: 5.1869 - val_kl: 0.0345 - val_mmd: 0.0000e+00\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3318 - recon: 5.3031 - kl: 0.0287 - mmd: 0.0000e+00 - val_loss: 5.2178 - val_recon: 5.1849 - val_kl: 0.0328 - val_mmd: 0.0000e+00\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3310 - recon: 5.3035 - kl: 0.0275 - mmd: 0.0000e+00 - val_loss: 5.2124 - val_recon: 5.1809 - val_kl: 0.0315 - val_mmd: 0.0000e+00\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3289 - recon: 5.3025 - kl: 0.0264 - mmd: 0.0000e+00 - val_loss: 5.2099 - val_recon: 5.1798 - val_kl: 0.0301 - val_mmd: 0.0000e+00\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3284 - recon: 5.3031 - kl: 0.0253 - mmd: 0.0000e+00 - val_loss: 5.2093 - val_recon: 5.1806 - val_kl: 0.0288 - val_mmd: 0.0000e+00\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3265 - recon: 5.3022 - kl: 0.0242 - mmd: 0.0000e+00 - val_loss: 5.2073 - val_recon: 5.1797 - val_kl: 0.0276 - val_mmd: 0.0000e+00\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3238 - recon: 5.3006 - kl: 0.0232 - mmd: 0.0000e+00 - val_loss: 5.2038 - val_recon: 5.1776 - val_kl: 0.0262 - val_mmd: 0.0000e+00\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3236 - recon: 5.3014 - kl: 0.0222 - mmd: 0.0000e+00 - val_loss: 5.2071 - val_recon: 5.1819 - val_kl: 0.0252 - val_mmd: 0.0000e+00\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3203 - recon: 5.2991 - kl: 0.0212 - mmd: 0.0000e+00 - val_loss: 5.2034 - val_recon: 5.1795 - val_kl: 0.0239 - val_mmd: 0.0000e+00\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3205 - recon: 5.3002 - kl: 0.0203 - mmd: 0.0000e+00 - val_loss: 5.2013 - val_recon: 5.1786 - val_kl: 0.0228 - val_mmd: 0.0000e+00\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3194 - recon: 5.3000 - kl: 0.0194 - mmd: 0.0000e+00 - val_loss: 5.2101 - val_recon: 5.1885 - val_kl: 0.0216 - val_mmd: 0.0000e+00\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3190 - recon: 5.3005 - kl: 0.0185 - mmd: 0.0000e+00 - val_loss: 5.1989 - val_recon: 5.1782 - val_kl: 0.0207 - val_mmd: 0.0000e+00\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3172 - recon: 5.2996 - kl: 0.0176 - mmd: 0.0000e+00 - val_loss: 5.1974 - val_recon: 5.1777 - val_kl: 0.0197 - val_mmd: 0.0000e+00\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3188 - recon: 5.3020 - kl: 0.0167 - mmd: 0.0000e+00 - val_loss: 5.1953 - val_recon: 5.1767 - val_kl: 0.0186 - val_mmd: 0.0000e+00\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3140 - recon: 5.2981 - kl: 0.0159 - mmd: 0.0000e+00 - val_loss: 5.1975 - val_recon: 5.1798 - val_kl: 0.0177 - val_mmd: 0.0000e+00\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3136 - recon: 5.2985 - kl: 0.0151 - mmd: 0.0000e+00 - val_loss: 5.1870 - val_recon: 5.1703 - val_kl: 0.0167 - val_mmd: 0.0000e+00\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3117 - recon: 5.2974 - kl: 0.0143 - mmd: 0.0000e+00 - val_loss: 5.2023 - val_recon: 5.1866 - val_kl: 0.0157 - val_mmd: 0.0000e+00\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3130 - recon: 5.2995 - kl: 0.0135 - mmd: 0.0000e+00 - val_loss: 5.2002 - val_recon: 5.1854 - val_kl: 0.0148 - val_mmd: 0.0000e+00\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3110 - recon: 5.2983 - kl: 0.0127 - mmd: 0.0000e+00 - val_loss: 5.1903 - val_recon: 5.1765 - val_kl: 0.0138 - val_mmd: 0.0000e+00\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3089 - recon: 5.2969 - kl: 0.0119 - mmd: 0.0000e+00 - val_loss: 5.1900 - val_recon: 5.1770 - val_kl: 0.0130 - val_mmd: 0.0000e+00\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3102 - recon: 5.2990 - kl: 0.0112 - mmd: 0.0000e+00 - val_loss: 5.1897 - val_recon: 5.1775 - val_kl: 0.0122 - val_mmd: 0.0000e+00\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3084 - recon: 5.2979 - kl: 0.0105 - mmd: 0.0000e+00 - val_loss: 5.1915 - val_recon: 5.1801 - val_kl: 0.0114 - val_mmd: 0.0000e+00\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3078 - recon: 5.2980 - kl: 0.0098 - mmd: 0.0000e+00 - val_loss: 5.1900 - val_recon: 5.1794 - val_kl: 0.0106 - val_mmd: 0.0000e+00\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3041 - recon: 5.2950 - kl: 0.0091 - mmd: 0.0000e+00 - val_loss: 5.1830 - val_recon: 5.1731 - val_kl: 0.0099 - val_mmd: 0.0000e+00\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3047 - recon: 5.2963 - kl: 0.0084 - mmd: 0.0000e+00 - val_loss: 5.1804 - val_recon: 5.1712 - val_kl: 0.0091 - val_mmd: 0.0000e+00\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3033 - recon: 5.2955 - kl: 0.0078 - mmd: 0.0000e+00 - val_loss: 5.1816 - val_recon: 5.1732 - val_kl: 0.0084 - val_mmd: 0.0000e+00\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3021 - recon: 5.2949 - kl: 0.0072 - mmd: 0.0000e+00 - val_loss: 5.1808 - val_recon: 5.1731 - val_kl: 0.0077 - val_mmd: 0.0000e+00\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3035 - recon: 5.2969 - kl: 0.0066 - mmd: 0.0000e+00 - val_loss: 5.1828 - val_recon: 5.1757 - val_kl: 0.0071 - val_mmd: 0.0000e+00\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3008 - recon: 5.2948 - kl: 0.0060 - mmd: 0.0000e+00 - val_loss: 5.1778 - val_recon: 5.1714 - val_kl: 0.0065 - val_mmd: 0.0000e+00\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2997 - recon: 5.2942 - kl: 0.0055 - mmd: 0.0000e+00 - val_loss: 5.1850 - val_recon: 5.1791 - val_kl: 0.0059 - val_mmd: 0.0000e+00\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2995 - recon: 5.2945 - kl: 0.0050 - mmd: 0.0000e+00 - val_loss: 5.1842 - val_recon: 5.1789 - val_kl: 0.0053 - val_mmd: 0.0000e+00\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3010 - recon: 5.2965 - kl: 0.0045 - mmd: 0.0000e+00 - val_loss: 5.1763 - val_recon: 5.1716 - val_kl: 0.0048 - val_mmd: 0.0000e+00\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2977 - recon: 5.2936 - kl: 0.0041 - mmd: 0.0000e+00 - val_loss: 5.1797 - val_recon: 5.1754 - val_kl: 0.0043 - val_mmd: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2987 - recon: 5.2951 - kl: 0.0036 - mmd: 0.0000e+00 - val_loss: 5.1765 - val_recon: 5.1726 - val_kl: 0.0038 - val_mmd: 0.0000e+00\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2992 - recon: 5.2959 - kl: 0.0033 - mmd: 0.0000e+00 - val_loss: 5.1834 - val_recon: 5.1800 - val_kl: 0.0034 - val_mmd: 0.0000e+00\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2964 - recon: 5.2935 - kl: 0.0029 - mmd: 0.0000e+00 - val_loss: 5.1788 - val_recon: 5.1758 - val_kl: 0.0030 - val_mmd: 0.0000e+00\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2967 - recon: 5.2942 - kl: 0.0026 - mmd: 0.0000e+00 - val_loss: 5.1744 - val_recon: 5.1717 - val_kl: 0.0027 - val_mmd: 0.0000e+00\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2952 - recon: 5.2930 - kl: 0.0023 - mmd: 0.0000e+00 - val_loss: 5.1746 - val_recon: 5.1723 - val_kl: 0.0023 - val_mmd: 0.0000e+00\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2950 - recon: 5.2930 - kl: 0.0020 - mmd: 0.0000e+00 - val_loss: 5.1700 - val_recon: 5.1680 - val_kl: 0.0021 - val_mmd: 0.0000e+00\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2939 - recon: 5.2921 - kl: 0.0017 - mmd: 0.0000e+00 - val_loss: 5.1754 - val_recon: 5.1737 - val_kl: 0.0018 - val_mmd: 0.0000e+00\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2947 - recon: 5.2932 - kl: 0.0015 - mmd: 0.0000e+00 - val_loss: 5.1706 - val_recon: 5.1691 - val_kl: 0.0015 - val_mmd: 0.0000e+00\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2954 - recon: 5.2941 - kl: 0.0013 - mmd: 0.0000e+00 - val_loss: 5.1733 - val_recon: 5.1719 - val_kl: 0.0013 - val_mmd: 0.0000e+00\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2937 - recon: 5.2926 - kl: 0.0011 - mmd: 0.0000e+00 - val_loss: 5.1701 - val_recon: 5.1689 - val_kl: 0.0011 - val_mmd: 0.0000e+00\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2928 - recon: 5.2919 - kl: 9.5851e-04 - mmd: 0.0000e+00 - val_loss: 5.1698 - val_recon: 5.1689 - val_kl: 9.6344e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2933 - recon: 5.2925 - kl: 8.1901e-04 - mmd: 0.0000e+00 - val_loss: 5.1701 - val_recon: 5.1693 - val_kl: 8.1842e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2902 - recon: 5.2895 - kl: 6.9075e-04 - mmd: 0.0000e+00 - val_loss: 5.1704 - val_recon: 5.1697 - val_kl: 6.9125e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2921 - recon: 5.2916 - kl: 5.8252e-04 - mmd: 0.0000e+00 - val_loss: 5.1674 - val_recon: 5.1669 - val_kl: 5.7717e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2906 - recon: 5.2901 - kl: 4.8870e-04 - mmd: 0.0000e+00 - val_loss: 5.1682 - val_recon: 5.1677 - val_kl: 4.8624e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2908 - recon: 5.2903 - kl: 4.0938e-04 - mmd: 0.0000e+00 - val_loss: 5.1723 - val_recon: 5.1719 - val_kl: 4.0548e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2920 - recon: 5.2916 - kl: 3.4337e-04 - mmd: 0.0000e+00 - val_loss: 5.1645 - val_recon: 5.1642 - val_kl: 3.3535e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2906 - recon: 5.2903 - kl: 2.8379e-04 - mmd: 0.0000e+00 - val_loss: 5.1700 - val_recon: 5.1697 - val_kl: 2.7383e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2908 - recon: 5.2905 - kl: 2.3428e-04 - mmd: 0.0000e+00 - val_loss: 5.1667 - val_recon: 5.1665 - val_kl: 2.2685e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2898 - recon: 5.2896 - kl: 1.9406e-04 - mmd: 0.0000e+00 - val_loss: 5.1697 - val_recon: 5.1695 - val_kl: 1.8872e-04 - val_mmd: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "cp_vae.train(x_train=train_features_df, x_test=valid_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd5bacb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f145ebd2250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_vae.vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d92dad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 01:45:37.187666: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/level5EncoderShuffled_beta/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/level5DecoderShuffled_beta/assets\n"
     ]
    }
   ],
   "source": [
    "encoder = cp_vae.encoder_block[\"encoder\"]\n",
    "decoder = cp_vae.decoder_block[\"decoder\"]\n",
    "encoder.save(\"models/level5EncoderShuffled_beta\")\n",
    "decoder.save(\"models/level5DecoderShuffled_beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0b78c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recon</th>\n",
       "      <th>kl</th>\n",
       "      <th>mmd</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recon</th>\n",
       "      <th>val_kl</th>\n",
       "      <th>val_mmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.419617</td>\n",
       "      <td>32.059681</td>\n",
       "      <td>1.359945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.527626</td>\n",
       "      <td>10.605546</td>\n",
       "      <td>0.922080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.541502</td>\n",
       "      <td>10.336514</td>\n",
       "      <td>1.204988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.761103</td>\n",
       "      <td>9.447875</td>\n",
       "      <td>1.313227</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.938849</td>\n",
       "      <td>7.884923</td>\n",
       "      <td>1.053928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.346759</td>\n",
       "      <td>11.633946</td>\n",
       "      <td>2.712813</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.469841</td>\n",
       "      <td>6.553485</td>\n",
       "      <td>0.916354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.100918</td>\n",
       "      <td>6.640206</td>\n",
       "      <td>1.460711</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.682912</td>\n",
       "      <td>5.885369</td>\n",
       "      <td>0.797541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.149210</td>\n",
       "      <td>5.897563</td>\n",
       "      <td>1.251648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.290754</td>\n",
       "      <td>5.290343</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.172284</td>\n",
       "      <td>5.171879</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.291967</td>\n",
       "      <td>5.291624</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.164517</td>\n",
       "      <td>5.164182</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.290632</td>\n",
       "      <td>5.290350</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.169976</td>\n",
       "      <td>5.169702</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.290751</td>\n",
       "      <td>5.290514</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.166712</td>\n",
       "      <td>5.166485</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.289812</td>\n",
       "      <td>5.289617</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.169686</td>\n",
       "      <td>5.169497</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss      recon        kl  mmd   val_loss  val_recon    val_kl  \\\n",
       "0   33.419617  32.059681  1.359945  0.0  11.527626  10.605546  0.922080   \n",
       "1   11.541502  10.336514  1.204988  0.0  10.761103   9.447875  1.313227   \n",
       "2    8.938849   7.884923  1.053928  0.0  14.346759  11.633946  2.712813   \n",
       "3    7.469841   6.553485  0.916354  0.0   8.100918   6.640206  1.460711   \n",
       "4    6.682912   5.885369  0.797541  0.0   7.149210   5.897563  1.251648   \n",
       "..        ...        ...       ...  ...        ...        ...       ...   \n",
       "95   5.290754   5.290343  0.000409  0.0   5.172284   5.171879  0.000405   \n",
       "96   5.291967   5.291624  0.000343  0.0   5.164517   5.164182  0.000335   \n",
       "97   5.290632   5.290350  0.000284  0.0   5.169976   5.169702  0.000274   \n",
       "98   5.290751   5.290514  0.000234  0.0   5.166712   5.166485  0.000227   \n",
       "99   5.289812   5.289617  0.000194  0.0   5.169686   5.169497  0.000189   \n",
       "\n",
       "    val_mmd  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "..      ...  \n",
       "95      0.0  \n",
       "96      0.0  \n",
       "97      0.0  \n",
       "98      0.0  \n",
       "99      0.0  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save training performance\n",
    "history_df = pd.DataFrame(cp_vae.vae.history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0d167dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_df.to_csv('level5_training_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371be6d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'level5_training.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_70274/3774497902.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moriginal_training_data\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'level5_training.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'level5_training.csv'"
     ]
    }
   ],
   "source": [
    "# original_training_data  = pd.read_csv('level5_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2d259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7, 5), dpi = 400)\n",
    "# plt.plot(original_training_data[\"loss\"], label=\"Training data\")\n",
    "# plt.plot(original_training_data[\"val_loss\"], label=\"Validation data\")\n",
    "# plt.plot(history_df[\"loss\"], label=\"Shuffled training data\")\n",
    "# plt.plot(history_df[\"val_loss\"], label=\"Shuffled validation data\")\n",
    "# # plt.title(\"Loss for VAE training on Cell Painting Level 5 data\")\n",
    "# plt.ylabel(\"MSE + KL Divergence\")\n",
    "# plt.xlabel(\"No. Epoch\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7841eb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "cp_vae = VAE(\n",
    "    input_dim=train_features_df.shape[1],\n",
    "    latent_dim=10,\n",
    "    batch_size=96,\n",
    "    encoder_batch_norm=True,\n",
    "    epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    encoder_architecture=encoder_architecture,\n",
    "    decoder_architecture=decoder_architecture,\n",
    "    beta=1,\n",
    "    verbose=True,\n",
    ")\n",
    "cp_vae.compile_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2541ec3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "87/87 [==============================] - 3s 13ms/step - loss: 36.9487 - recon: 32.5821 - kl: 4.3666 - mmd: 0.0000e+00 - val_loss: 15.1795 - val_recon: 12.0833 - val_kl: 3.0962 - val_mmd: 0.0000e+00\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.8791 - recon: 10.3486 - kl: 3.5305 - mmd: 0.0000e+00 - val_loss: 13.7657 - val_recon: 10.0466 - val_kl: 3.7191 - val_mmd: 0.0000e+00\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.6387 - recon: 7.8289 - kl: 2.8098 - mmd: 0.0000e+00 - val_loss: 12.4224 - val_recon: 8.3344 - val_kl: 4.0880 - val_mmd: 0.0000e+00\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.7534 - recon: 6.5319 - kl: 2.2216 - mmd: 0.0000e+00 - val_loss: 10.1248 - val_recon: 6.8207 - val_kl: 3.3041 - val_mmd: 0.0000e+00\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 7.6622 - recon: 5.8918 - kl: 1.7704 - mmd: 0.0000e+00 - val_loss: 8.4447 - val_recon: 5.8090 - val_kl: 2.6357 - val_mmd: 0.0000e+00\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 7.0261 - recon: 5.5957 - kl: 1.4304 - mmd: 0.0000e+00 - val_loss: 7.6246 - val_recon: 5.4929 - val_kl: 2.1317 - val_mmd: 0.0000e+00\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 6.6452 - recon: 5.4717 - kl: 1.1735 - mmd: 0.0000e+00 - val_loss: 6.8771 - val_recon: 5.3730 - val_kl: 1.5041 - val_mmd: 0.0000e+00\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 6.3859 - recon: 5.4094 - kl: 0.9765 - mmd: 0.0000e+00 - val_loss: 6.4446 - val_recon: 5.2960 - val_kl: 1.1486 - val_mmd: 0.0000e+00\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 6.2047 - recon: 5.3808 - kl: 0.8239 - mmd: 0.0000e+00 - val_loss: 6.2530 - val_recon: 5.2621 - val_kl: 0.9909 - val_mmd: 0.0000e+00\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 6.0680 - recon: 5.3644 - kl: 0.7036 - mmd: 0.0000e+00 - val_loss: 6.0422 - val_recon: 5.2378 - val_kl: 0.8044 - val_mmd: 0.0000e+00\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.9626 - recon: 5.3536 - kl: 0.6089 - mmd: 0.0000e+00 - val_loss: 5.9125 - val_recon: 5.2382 - val_kl: 0.6743 - val_mmd: 0.0000e+00\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.8785 - recon: 5.3463 - kl: 0.5322 - mmd: 0.0000e+00 - val_loss: 5.8098 - val_recon: 5.2207 - val_kl: 0.5891 - val_mmd: 0.0000e+00\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.8103 - recon: 5.3406 - kl: 0.4697 - mmd: 0.0000e+00 - val_loss: 5.7424 - val_recon: 5.2182 - val_kl: 0.5242 - val_mmd: 0.0000e+00\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.7560 - recon: 5.3372 - kl: 0.4188 - mmd: 0.0000e+00 - val_loss: 5.6739 - val_recon: 5.2178 - val_kl: 0.4561 - val_mmd: 0.0000e+00\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.7114 - recon: 5.3352 - kl: 0.3762 - mmd: 0.0000e+00 - val_loss: 5.6097 - val_recon: 5.2092 - val_kl: 0.4005 - val_mmd: 0.0000e+00\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.6718 - recon: 5.3314 - kl: 0.3404 - mmd: 0.0000e+00 - val_loss: 5.5840 - val_recon: 5.2118 - val_kl: 0.3722 - val_mmd: 0.0000e+00\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.6382 - recon: 5.3291 - kl: 0.3091 - mmd: 0.0000e+00 - val_loss: 5.5472 - val_recon: 5.2121 - val_kl: 0.3351 - val_mmd: 0.0000e+00\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.6110 - recon: 5.3287 - kl: 0.2823 - mmd: 0.0000e+00 - val_loss: 5.5153 - val_recon: 5.2061 - val_kl: 0.3092 - val_mmd: 0.0000e+00\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.5847 - recon: 5.3261 - kl: 0.2586 - mmd: 0.0000e+00 - val_loss: 5.4894 - val_recon: 5.2044 - val_kl: 0.2851 - val_mmd: 0.0000e+00\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.5638 - recon: 5.3258 - kl: 0.2379 - mmd: 0.0000e+00 - val_loss: 5.4710 - val_recon: 5.2090 - val_kl: 0.2620 - val_mmd: 0.0000e+00\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.5437 - recon: 5.3242 - kl: 0.2195 - mmd: 0.0000e+00 - val_loss: 5.4439 - val_recon: 5.2002 - val_kl: 0.2438 - val_mmd: 0.0000e+00\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.5253 - recon: 5.3224 - kl: 0.2029 - mmd: 0.0000e+00 - val_loss: 5.4375 - val_recon: 5.2091 - val_kl: 0.2284 - val_mmd: 0.0000e+00\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.5089 - recon: 5.3208 - kl: 0.1881 - mmd: 0.0000e+00 - val_loss: 5.4105 - val_recon: 5.2004 - val_kl: 0.2101 - val_mmd: 0.0000e+00\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4979 - recon: 5.3233 - kl: 0.1746 - mmd: 0.0000e+00 - val_loss: 5.4023 - val_recon: 5.2061 - val_kl: 0.1962 - val_mmd: 0.0000e+00\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4836 - recon: 5.3211 - kl: 0.1625 - mmd: 0.0000e+00 - val_loss: 5.3807 - val_recon: 5.1988 - val_kl: 0.1820 - val_mmd: 0.0000e+00\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4707 - recon: 5.3191 - kl: 0.1516 - mmd: 0.0000e+00 - val_loss: 5.3717 - val_recon: 5.2016 - val_kl: 0.1701 - val_mmd: 0.0000e+00\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4620 - recon: 5.3205 - kl: 0.1415 - mmd: 0.0000e+00 - val_loss: 5.3560 - val_recon: 5.1964 - val_kl: 0.1596 - val_mmd: 0.0000e+00\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4520 - recon: 5.3196 - kl: 0.1324 - mmd: 0.0000e+00 - val_loss: 5.3461 - val_recon: 5.1964 - val_kl: 0.1497 - val_mmd: 0.0000e+00\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4393 - recon: 5.3156 - kl: 0.1238 - mmd: 0.0000e+00 - val_loss: 5.3351 - val_recon: 5.1956 - val_kl: 0.1395 - val_mmd: 0.0000e+00\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4338 - recon: 5.3178 - kl: 0.1160 - mmd: 0.0000e+00 - val_loss: 5.3293 - val_recon: 5.1979 - val_kl: 0.1314 - val_mmd: 0.0000e+00\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4252 - recon: 5.3163 - kl: 0.1089 - mmd: 0.0000e+00 - val_loss: 5.3203 - val_recon: 5.1972 - val_kl: 0.1231 - val_mmd: 0.0000e+00\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4180 - recon: 5.3158 - kl: 0.1022 - mmd: 0.0000e+00 - val_loss: 5.3179 - val_recon: 5.2023 - val_kl: 0.1156 - val_mmd: 0.0000e+00\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4124 - recon: 5.3163 - kl: 0.0961 - mmd: 0.0000e+00 - val_loss: 5.3049 - val_recon: 5.1955 - val_kl: 0.1094 - val_mmd: 0.0000e+00\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.4042 - recon: 5.3136 - kl: 0.0905 - mmd: 0.0000e+00 - val_loss: 5.2920 - val_recon: 5.1892 - val_kl: 0.1027 - val_mmd: 0.0000e+00\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3980 - recon: 5.3128 - kl: 0.0852 - mmd: 0.0000e+00 - val_loss: 5.2908 - val_recon: 5.1947 - val_kl: 0.0961 - val_mmd: 0.0000e+00\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3939 - recon: 5.3138 - kl: 0.0801 - mmd: 0.0000e+00 - val_loss: 5.2863 - val_recon: 5.1955 - val_kl: 0.0908 - val_mmd: 0.0000e+00\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3881 - recon: 5.3127 - kl: 0.0754 - mmd: 0.0000e+00 - val_loss: 5.2751 - val_recon: 5.1898 - val_kl: 0.0852 - val_mmd: 0.0000e+00\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3813 - recon: 5.3102 - kl: 0.0711 - mmd: 0.0000e+00 - val_loss: 5.2693 - val_recon: 5.1894 - val_kl: 0.0799 - val_mmd: 0.0000e+00\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3777 - recon: 5.3107 - kl: 0.0669 - mmd: 0.0000e+00 - val_loss: 5.2676 - val_recon: 5.1919 - val_kl: 0.0757 - val_mmd: 0.0000e+00\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3720 - recon: 5.3091 - kl: 0.0629 - mmd: 0.0000e+00 - val_loss: 5.2614 - val_recon: 5.1906 - val_kl: 0.0708 - val_mmd: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3676 - recon: 5.3085 - kl: 0.0591 - mmd: 0.0000e+00 - val_loss: 5.2534 - val_recon: 5.1867 - val_kl: 0.0666 - val_mmd: 0.0000e+00\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3631 - recon: 5.3076 - kl: 0.0555 - mmd: 0.0000e+00 - val_loss: 5.2471 - val_recon: 5.1843 - val_kl: 0.0628 - val_mmd: 0.0000e+00\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3594 - recon: 5.3074 - kl: 0.0520 - mmd: 0.0000e+00 - val_loss: 5.2438 - val_recon: 5.1853 - val_kl: 0.0585 - val_mmd: 0.0000e+00\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3568 - recon: 5.3081 - kl: 0.0487 - mmd: 0.0000e+00 - val_loss: 5.2390 - val_recon: 5.1847 - val_kl: 0.0543 - val_mmd: 0.0000e+00\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3511 - recon: 5.3056 - kl: 0.0455 - mmd: 0.0000e+00 - val_loss: 5.2385 - val_recon: 5.1876 - val_kl: 0.0508 - val_mmd: 0.0000e+00\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3480 - recon: 5.3055 - kl: 0.0424 - mmd: 0.0000e+00 - val_loss: 5.2324 - val_recon: 5.1848 - val_kl: 0.0476 - val_mmd: 0.0000e+00\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3448 - recon: 5.3053 - kl: 0.0395 - mmd: 0.0000e+00 - val_loss: 5.2323 - val_recon: 5.1883 - val_kl: 0.0440 - val_mmd: 0.0000e+00\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3410 - recon: 5.3044 - kl: 0.0366 - mmd: 0.0000e+00 - val_loss: 5.2262 - val_recon: 5.1853 - val_kl: 0.0409 - val_mmd: 0.0000e+00\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3374 - recon: 5.3036 - kl: 0.0339 - mmd: 0.0000e+00 - val_loss: 5.2210 - val_recon: 5.1833 - val_kl: 0.0376 - val_mmd: 0.0000e+00\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3356 - recon: 5.3043 - kl: 0.0312 - mmd: 0.0000e+00 - val_loss: 5.2205 - val_recon: 5.1860 - val_kl: 0.0345 - val_mmd: 0.0000e+00\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3314 - recon: 5.3027 - kl: 0.0287 - mmd: 0.0000e+00 - val_loss: 5.2141 - val_recon: 5.1823 - val_kl: 0.0318 - val_mmd: 0.0000e+00\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3308 - recon: 5.3045 - kl: 0.0263 - mmd: 0.0000e+00 - val_loss: 5.2107 - val_recon: 5.1817 - val_kl: 0.0290 - val_mmd: 0.0000e+00\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3277 - recon: 5.3037 - kl: 0.0240 - mmd: 0.0000e+00 - val_loss: 5.2091 - val_recon: 5.1827 - val_kl: 0.0265 - val_mmd: 0.0000e+00\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3250 - recon: 5.3031 - kl: 0.0218 - mmd: 0.0000e+00 - val_loss: 5.1989 - val_recon: 5.1751 - val_kl: 0.0239 - val_mmd: 0.0000e+00\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3220 - recon: 5.3022 - kl: 0.0198 - mmd: 0.0000e+00 - val_loss: 5.2041 - val_recon: 5.1823 - val_kl: 0.0217 - val_mmd: 0.0000e+00\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3192 - recon: 5.3014 - kl: 0.0178 - mmd: 0.0000e+00 - val_loss: 5.1937 - val_recon: 5.1742 - val_kl: 0.0195 - val_mmd: 0.0000e+00\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3175 - recon: 5.3015 - kl: 0.0160 - mmd: 0.0000e+00 - val_loss: 5.1993 - val_recon: 5.1819 - val_kl: 0.0173 - val_mmd: 0.0000e+00\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3182 - recon: 5.3039 - kl: 0.0143 - mmd: 0.0000e+00 - val_loss: 5.1944 - val_recon: 5.1789 - val_kl: 0.0155 - val_mmd: 0.0000e+00\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3132 - recon: 5.3004 - kl: 0.0127 - mmd: 0.0000e+00 - val_loss: 5.1953 - val_recon: 5.1817 - val_kl: 0.0137 - val_mmd: 0.0000e+00\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3126 - recon: 5.3014 - kl: 0.0112 - mmd: 0.0000e+00 - val_loss: 5.1885 - val_recon: 5.1764 - val_kl: 0.0120 - val_mmd: 0.0000e+00\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3092 - recon: 5.2993 - kl: 0.0099 - mmd: 0.0000e+00 - val_loss: 5.1911 - val_recon: 5.1805 - val_kl: 0.0105 - val_mmd: 0.0000e+00\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3082 - recon: 5.2995 - kl: 0.0087 - mmd: 0.0000e+00 - val_loss: 5.1828 - val_recon: 5.1736 - val_kl: 0.0092 - val_mmd: 0.0000e+00\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3061 - recon: 5.2986 - kl: 0.0075 - mmd: 0.0000e+00 - val_loss: 5.1879 - val_recon: 5.1799 - val_kl: 0.0080 - val_mmd: 0.0000e+00\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3049 - recon: 5.2984 - kl: 0.0065 - mmd: 0.0000e+00 - val_loss: 5.1862 - val_recon: 5.1793 - val_kl: 0.0069 - val_mmd: 0.0000e+00\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3054 - recon: 5.2998 - kl: 0.0056 - mmd: 0.0000e+00 - val_loss: 5.1849 - val_recon: 5.1791 - val_kl: 0.0059 - val_mmd: 0.0000e+00\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3022 - recon: 5.2974 - kl: 0.0048 - mmd: 0.0000e+00 - val_loss: 5.1822 - val_recon: 5.1772 - val_kl: 0.0050 - val_mmd: 0.0000e+00\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3024 - recon: 5.2984 - kl: 0.0040 - mmd: 0.0000e+00 - val_loss: 5.1824 - val_recon: 5.1782 - val_kl: 0.0042 - val_mmd: 0.0000e+00\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3012 - recon: 5.2978 - kl: 0.0034 - mmd: 0.0000e+00 - val_loss: 5.1788 - val_recon: 5.1753 - val_kl: 0.0035 - val_mmd: 0.0000e+00\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3001 - recon: 5.2972 - kl: 0.0028 - mmd: 0.0000e+00 - val_loss: 5.1815 - val_recon: 5.1785 - val_kl: 0.0029 - val_mmd: 0.0000e+00\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2994 - recon: 5.2970 - kl: 0.0024 - mmd: 0.0000e+00 - val_loss: 5.1796 - val_recon: 5.1772 - val_kl: 0.0024 - val_mmd: 0.0000e+00\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3025 - recon: 5.3005 - kl: 0.0019 - mmd: 0.0000e+00 - val_loss: 5.1808 - val_recon: 5.1788 - val_kl: 0.0020 - val_mmd: 0.0000e+00\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2985 - recon: 5.2969 - kl: 0.0016 - mmd: 0.0000e+00 - val_loss: 5.1883 - val_recon: 5.1867 - val_kl: 0.0016 - val_mmd: 0.0000e+00\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.3007 - recon: 5.2994 - kl: 0.0013 - mmd: 0.0000e+00 - val_loss: 5.1787 - val_recon: 5.1774 - val_kl: 0.0013 - val_mmd: 0.0000e+00\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2972 - recon: 5.2962 - kl: 0.0010 - mmd: 0.0000e+00 - val_loss: 5.1709 - val_recon: 5.1698 - val_kl: 0.0010 - val_mmd: 0.0000e+00\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2986 - recon: 5.2978 - kl: 8.2997e-04 - mmd: 0.0000e+00 - val_loss: 5.1894 - val_recon: 5.1886 - val_kl: 8.2277e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2990 - recon: 5.2983 - kl: 6.5905e-04 - mmd: 0.0000e+00 - val_loss: 5.1866 - val_recon: 5.1860 - val_kl: 6.4756e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2989 - recon: 5.2984 - kl: 5.2054e-04 - mmd: 0.0000e+00 - val_loss: 5.1790 - val_recon: 5.1785 - val_kl: 5.0924e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2979 - recon: 5.2975 - kl: 4.0962e-04 - mmd: 0.0000e+00 - val_loss: 5.1712 - val_recon: 5.1708 - val_kl: 3.9541e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2960 - recon: 5.2957 - kl: 3.1822e-04 - mmd: 0.0000e+00 - val_loss: 5.1793 - val_recon: 5.1790 - val_kl: 3.0270e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2958 - recon: 5.2956 - kl: 2.4487e-04 - mmd: 0.0000e+00 - val_loss: 5.1737 - val_recon: 5.1735 - val_kl: 2.3205e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2956 - recon: 5.2954 - kl: 1.8635e-04 - mmd: 0.0000e+00 - val_loss: 5.1828 - val_recon: 5.1826 - val_kl: 1.7498e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2955 - recon: 5.2954 - kl: 1.4455e-04 - mmd: 0.0000e+00 - val_loss: 5.1729 - val_recon: 5.1728 - val_kl: 1.3339e-04 - val_mmd: 0.0000e+00\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2935 - recon: 5.2933 - kl: 1.0804e-04 - mmd: 0.0000e+00 - val_loss: 5.1754 - val_recon: 5.1753 - val_kl: 9.9703e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2936 - recon: 5.2935 - kl: 8.0908e-05 - mmd: 0.0000e+00 - val_loss: 5.1745 - val_recon: 5.1744 - val_kl: 7.4439e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2935 - recon: 5.2935 - kl: 6.1868e-05 - mmd: 0.0000e+00 - val_loss: 5.1713 - val_recon: 5.1713 - val_kl: 5.5733e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2928 - recon: 5.2927 - kl: 4.6360e-05 - mmd: 0.0000e+00 - val_loss: 5.1735 - val_recon: 5.1735 - val_kl: 4.2415e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2945 - recon: 5.2945 - kl: 3.7338e-05 - mmd: 0.0000e+00 - val_loss: 5.1777 - val_recon: 5.1776 - val_kl: 3.3232e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2954 - recon: 5.2953 - kl: 2.9201e-05 - mmd: 0.0000e+00 - val_loss: 5.1811 - val_recon: 5.1810 - val_kl: 2.7028e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2941 - recon: 5.2940 - kl: 2.4658e-05 - mmd: 0.0000e+00 - val_loss: 5.1749 - val_recon: 5.1749 - val_kl: 2.2268e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2922 - recon: 5.2922 - kl: 2.0057e-05 - mmd: 0.0000e+00 - val_loss: 5.1687 - val_recon: 5.1687 - val_kl: 1.7529e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2945 - recon: 5.2945 - kl: 1.7389e-05 - mmd: 0.0000e+00 - val_loss: 5.1808 - val_recon: 5.1807 - val_kl: 1.5802e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2923 - recon: 5.2923 - kl: 1.4230e-05 - mmd: 0.0000e+00 - val_loss: 5.1668 - val_recon: 5.1667 - val_kl: 1.2932e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2922 - recon: 5.2922 - kl: 1.2441e-05 - mmd: 0.0000e+00 - val_loss: 5.1637 - val_recon: 5.1637 - val_kl: 1.2090e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2930 - recon: 5.2930 - kl: 1.1151e-05 - mmd: 0.0000e+00 - val_loss: 5.1695 - val_recon: 5.1695 - val_kl: 1.2873e-05 - val_mmd: 0.0000e+00\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2917 - recon: 5.2917 - kl: 1.1784e-05 - mmd: 0.0000e+00 - val_loss: 5.1682 - val_recon: 5.1682 - val_kl: 9.9593e-06 - val_mmd: 0.0000e+00\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2909 - recon: 5.2909 - kl: 9.7393e-06 - mmd: 0.0000e+00 - val_loss: 5.1666 - val_recon: 5.1666 - val_kl: 8.6192e-06 - val_mmd: 0.0000e+00\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2904 - recon: 5.2904 - kl: 7.9763e-06 - mmd: 0.0000e+00 - val_loss: 5.1737 - val_recon: 5.1737 - val_kl: 7.6266e-06 - val_mmd: 0.0000e+00\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2911 - recon: 5.2911 - kl: 8.0465e-06 - mmd: 0.0000e+00 - val_loss: 5.1696 - val_recon: 5.1695 - val_kl: 8.1190e-06 - val_mmd: 0.0000e+00\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2901 - recon: 5.2901 - kl: 8.0765e-06 - mmd: 0.0000e+00 - val_loss: 5.1651 - val_recon: 5.1651 - val_kl: 6.9885e-06 - val_mmd: 0.0000e+00\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.2905 - recon: 5.2905 - kl: 7.2683e-06 - mmd: 0.0000e+00 - val_loss: 5.1772 - val_recon: 5.1772 - val_kl: 1.1418e-05 - val_mmd: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "cp_vae.train(x_train=train_features_df, x_test=valid_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31e7e53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f1418731e50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_vae.vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74c4e6ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recon</th>\n",
       "      <th>kl</th>\n",
       "      <th>mmd</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recon</th>\n",
       "      <th>val_kl</th>\n",
       "      <th>val_mmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.948734</td>\n",
       "      <td>32.582123</td>\n",
       "      <td>4.366626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.179503</td>\n",
       "      <td>12.083273</td>\n",
       "      <td>3.096229</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.879109</td>\n",
       "      <td>10.348588</td>\n",
       "      <td>3.530521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.765688</td>\n",
       "      <td>10.046631</td>\n",
       "      <td>3.719057</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.638667</td>\n",
       "      <td>7.828871</td>\n",
       "      <td>2.809797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.422438</td>\n",
       "      <td>8.334407</td>\n",
       "      <td>4.088029</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.753426</td>\n",
       "      <td>6.531874</td>\n",
       "      <td>2.221552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.124815</td>\n",
       "      <td>6.820738</td>\n",
       "      <td>3.304077</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.662220</td>\n",
       "      <td>5.891835</td>\n",
       "      <td>1.770385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.444698</td>\n",
       "      <td>5.809000</td>\n",
       "      <td>2.635699</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.290924</td>\n",
       "      <td>5.290915</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.166611</td>\n",
       "      <td>5.166602</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.290392</td>\n",
       "      <td>5.290384</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.173748</td>\n",
       "      <td>5.173740</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.291130</td>\n",
       "      <td>5.291122</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.169553</td>\n",
       "      <td>5.169545</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.290127</td>\n",
       "      <td>5.290120</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.165061</td>\n",
       "      <td>5.165055</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.290496</td>\n",
       "      <td>5.290491</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.177177</td>\n",
       "      <td>5.177166</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss      recon        kl  mmd   val_loss  val_recon    val_kl  \\\n",
       "0   36.948734  32.582123  4.366626  0.0  15.179503  12.083273  3.096229   \n",
       "1   13.879109  10.348588  3.530521  0.0  13.765688  10.046631  3.719057   \n",
       "2   10.638667   7.828871  2.809797  0.0  12.422438   8.334407  4.088029   \n",
       "3    8.753426   6.531874  2.221552  0.0  10.124815   6.820738  3.304077   \n",
       "4    7.662220   5.891835  1.770385  0.0   8.444698   5.809000  2.635699   \n",
       "..        ...        ...       ...  ...        ...        ...       ...   \n",
       "95   5.290924   5.290915  0.000010  0.0   5.166611   5.166602  0.000009   \n",
       "96   5.290392   5.290384  0.000008  0.0   5.173748   5.173740  0.000008   \n",
       "97   5.291130   5.291122  0.000008  0.0   5.169553   5.169545  0.000008   \n",
       "98   5.290127   5.290120  0.000008  0.0   5.165061   5.165055  0.000007   \n",
       "99   5.290496   5.290491  0.000007  0.0   5.177177   5.177166  0.000011   \n",
       "\n",
       "    val_mmd  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "..      ...  \n",
       "95      0.0  \n",
       "96      0.0  \n",
       "97      0.0  \n",
       "98      0.0  \n",
       "99      0.0  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save training performance\n",
    "history_df = pd.DataFrame(cp_vae.vae.history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa5d4b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/level5EncoderShuffled_vanilla/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/level5DecoderShuffled_vanilla/assets\n"
     ]
    }
   ],
   "source": [
    "encoder = cp_vae.encoder_block[\"encoder\"]\n",
    "decoder = cp_vae.decoder_block[\"decoder\"]\n",
    "encoder.save(\"models/level5EncoderShuffled_vanilla\")\n",
    "decoder.save(\"models/level5DecoderShuffled_vanilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b80badd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_df.to_csv('level5_training_vanilla_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2fe62eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'level5_training_vanilla.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_70274/644953025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moriginal_training_data\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'level5_training_vanilla.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'level5_training_vanilla.csv'"
     ]
    }
   ],
   "source": [
    "# original_training_data  = pd.read_csv('level5_training_vanilla.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a2e768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7, 5), dpi = 400)\n",
    "# plt.plot(original_training_data[\"loss\"], label=\"Training data\")\n",
    "# plt.plot(original_training_data[\"val_loss\"], label=\"Validation data\")\n",
    "# plt.plot(history_df[\"loss\"], label=\"Shuffled training data\")\n",
    "# plt.plot(history_df[\"val_loss\"], label=\"Shuffled validation data\")\n",
    "# # plt.title(\"Loss for VAE training on Cell Painting Level 5 data\")\n",
    "# plt.ylabel(\"MSE + KL Divergence\")\n",
    "# plt.xlabel(\"No. Epoch\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "759461ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "cp_vae = VAE(\n",
    "    input_dim=train_features_df.shape[1],\n",
    "    latent_dim=10,\n",
    "    batch_size=96,\n",
    "    encoder_batch_norm=True,\n",
    "    epochs=30,\n",
    "    learning_rate=0.001,\n",
    "    encoder_architecture=encoder_architecture,\n",
    "    decoder_architecture=decoder_architecture,\n",
    "    beta=0,\n",
    "    lam=1000,\n",
    "    verbose=True,\n",
    ")\n",
    "cp_vae.compile_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c3fb283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "87/87 [==============================] - 3s 13ms/step - loss: 53.2570 - recon: 33.4957 - kl: 0.0000e+00 - mmd: 20.1500 - val_loss: 55.2956 - val_recon: 10.6316 - val_kl: 0.0000e+00 - val_mmd: 42.8630\n",
      "Epoch 2/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 23.4737 - recon: 10.3543 - kl: 0.0000e+00 - mmd: 12.9835 - val_loss: 50.4096 - val_recon: 10.1527 - val_kl: 0.0000e+00 - val_mmd: 44.7478\n",
      "Epoch 3/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 17.2503 - recon: 7.7502 - kl: 0.0000e+00 - mmd: 9.4217 - val_loss: 114.0227 - val_recon: 14.4192 - val_kl: 0.0000e+00 - val_mmd: 97.5239\n",
      "Epoch 4/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.6136 - recon: 6.4237 - kl: 0.0000e+00 - mmd: 7.1246 - val_loss: 65.2234 - val_recon: 6.9797 - val_kl: 0.0000e+00 - val_mmd: 58.4609\n",
      "Epoch 5/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.6580 - recon: 5.8392 - kl: 0.0000e+00 - mmd: 5.9652 - val_loss: 93.6862 - val_recon: 6.7594 - val_kl: 0.0000e+00 - val_mmd: 86.9748\n",
      "Epoch 6/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1684 - recon: 5.5766 - kl: 0.0000e+00 - mmd: 4.6966 - val_loss: 42.9584 - val_recon: 5.7221 - val_kl: 0.0000e+00 - val_mmd: 34.7966\n",
      "Epoch 7/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8311 - recon: 5.4651 - kl: 0.0000e+00 - mmd: 4.5911 - val_loss: 17.2520 - val_recon: 5.3866 - val_kl: 0.0000e+00 - val_mmd: 13.4008\n",
      "Epoch 8/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6506 - recon: 5.4113 - kl: 0.0000e+00 - mmd: 4.3065 - val_loss: 30.6744 - val_recon: 5.3127 - val_kl: 0.0000e+00 - val_mmd: 26.3839\n",
      "Epoch 9/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5349 - recon: 5.3792 - kl: 0.0000e+00 - mmd: 4.2708 - val_loss: 21.9329 - val_recon: 5.2945 - val_kl: 0.0000e+00 - val_mmd: 17.7082\n",
      "Epoch 10/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3596 - recon: 5.3637 - kl: 0.0000e+00 - mmd: 4.0611 - val_loss: 54.0981 - val_recon: 5.3075 - val_kl: 0.0000e+00 - val_mmd: 53.5015\n",
      "Epoch 11/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3674 - recon: 5.3533 - kl: 0.0000e+00 - mmd: 3.8211 - val_loss: 27.3376 - val_recon: 5.2437 - val_kl: 0.0000e+00 - val_mmd: 20.9140\n",
      "Epoch 12/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.0696 - recon: 5.3434 - kl: 0.0000e+00 - mmd: 3.7380 - val_loss: 23.5996 - val_recon: 5.2255 - val_kl: 0.0000e+00 - val_mmd: 17.4518\n",
      "Epoch 13/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.0264 - recon: 5.3351 - kl: 0.0000e+00 - mmd: 3.3925 - val_loss: 50.0748 - val_recon: 5.2377 - val_kl: 0.0000e+00 - val_mmd: 40.3261\n",
      "Epoch 14/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.0078 - recon: 5.3344 - kl: 0.0000e+00 - mmd: 3.7552 - val_loss: 28.3208 - val_recon: 5.2253 - val_kl: 0.0000e+00 - val_mmd: 22.0351\n",
      "Epoch 15/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.8980 - recon: 5.3276 - kl: 0.0000e+00 - mmd: 3.6719 - val_loss: 24.6015 - val_recon: 5.2171 - val_kl: 0.0000e+00 - val_mmd: 17.1183\n",
      "Epoch 16/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.8009 - recon: 5.3242 - kl: 0.0000e+00 - mmd: 3.7259 - val_loss: 22.5746 - val_recon: 5.2125 - val_kl: 0.0000e+00 - val_mmd: 18.4431\n",
      "Epoch 17/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.1394 - recon: 5.3222 - kl: 0.0000e+00 - mmd: 3.9051 - val_loss: 22.1106 - val_recon: 5.2109 - val_kl: 0.0000e+00 - val_mmd: 18.5471\n",
      "Epoch 18/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.7419 - recon: 5.3200 - kl: 0.0000e+00 - mmd: 3.5591 - val_loss: 25.1701 - val_recon: 5.2050 - val_kl: 0.0000e+00 - val_mmd: 21.2606\n",
      "Epoch 19/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.9808 - recon: 5.3184 - kl: 0.0000e+00 - mmd: 3.6144 - val_loss: 22.0341 - val_recon: 5.2002 - val_kl: 0.0000e+00 - val_mmd: 16.9670\n",
      "Epoch 20/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.0474 - recon: 5.3172 - kl: 0.0000e+00 - mmd: 3.7611 - val_loss: 53.8444 - val_recon: 5.2092 - val_kl: 0.0000e+00 - val_mmd: 49.5222\n",
      "Epoch 21/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.0706 - recon: 5.3150 - kl: 0.0000e+00 - mmd: 3.5478 - val_loss: 17.2810 - val_recon: 5.2032 - val_kl: 0.0000e+00 - val_mmd: 12.7014\n",
      "Epoch 22/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.9529 - recon: 5.3113 - kl: 0.0000e+00 - mmd: 3.7639 - val_loss: 14.6162 - val_recon: 5.1927 - val_kl: 0.0000e+00 - val_mmd: 10.5724\n",
      "Epoch 23/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.7889 - recon: 5.3108 - kl: 0.0000e+00 - mmd: 3.5487 - val_loss: 27.7480 - val_recon: 5.1941 - val_kl: 0.0000e+00 - val_mmd: 23.9635\n",
      "Epoch 24/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.9741 - recon: 5.3094 - kl: 0.0000e+00 - mmd: 3.6649 - val_loss: 18.9589 - val_recon: 5.1937 - val_kl: 0.0000e+00 - val_mmd: 14.7559\n",
      "Epoch 25/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.7725 - recon: 5.3092 - kl: 0.0000e+00 - mmd: 3.7425 - val_loss: 18.5218 - val_recon: 5.1900 - val_kl: 0.0000e+00 - val_mmd: 13.0622\n",
      "Epoch 26/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.0956 - recon: 5.3073 - kl: 0.0000e+00 - mmd: 3.4543 - val_loss: 16.4019 - val_recon: 5.1923 - val_kl: 0.0000e+00 - val_mmd: 12.2944\n",
      "Epoch 27/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.9588 - recon: 5.3089 - kl: 0.0000e+00 - mmd: 3.7416 - val_loss: 15.0679 - val_recon: 5.1975 - val_kl: 0.0000e+00 - val_mmd: 9.8723\n",
      "Epoch 28/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.7471 - recon: 5.3044 - kl: 0.0000e+00 - mmd: 3.8202 - val_loss: 12.5142 - val_recon: 5.1921 - val_kl: 0.0000e+00 - val_mmd: 7.2475\n",
      "Epoch 29/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.5784 - recon: 5.3047 - kl: 0.0000e+00 - mmd: 3.2864 - val_loss: 16.2825 - val_recon: 5.1917 - val_kl: 0.0000e+00 - val_mmd: 13.5521\n",
      "Epoch 30/30\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 8.7340 - recon: 5.3038 - kl: 0.0000e+00 - mmd: 3.5550 - val_loss: 18.1663 - val_recon: 5.1869 - val_kl: 0.0000e+00 - val_mmd: 12.0426\n"
     ]
    }
   ],
   "source": [
    "cp_vae.train(x_train=train_features_df, x_test=valid_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dd06c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f13fc7dac90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_vae.vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51e3b23a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recon</th>\n",
       "      <th>kl</th>\n",
       "      <th>mmd</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recon</th>\n",
       "      <th>val_kl</th>\n",
       "      <th>val_mmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.256985</td>\n",
       "      <td>33.495697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.150007</td>\n",
       "      <td>55.295570</td>\n",
       "      <td>10.631577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.863033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.473732</td>\n",
       "      <td>10.354336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.983544</td>\n",
       "      <td>50.409554</td>\n",
       "      <td>10.152746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.747761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.250278</td>\n",
       "      <td>7.750245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.421741</td>\n",
       "      <td>114.022728</td>\n",
       "      <td>14.419161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.523895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.613574</td>\n",
       "      <td>6.423739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.124564</td>\n",
       "      <td>65.223373</td>\n",
       "      <td>6.979677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.460938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.657954</td>\n",
       "      <td>5.839181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.965222</td>\n",
       "      <td>93.686180</td>\n",
       "      <td>6.759391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.974808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.168350</td>\n",
       "      <td>5.576635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.696644</td>\n",
       "      <td>42.958366</td>\n",
       "      <td>5.722135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.796650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.831089</td>\n",
       "      <td>5.465136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.591119</td>\n",
       "      <td>17.252010</td>\n",
       "      <td>5.386589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.400815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.650624</td>\n",
       "      <td>5.411336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.306530</td>\n",
       "      <td>30.674387</td>\n",
       "      <td>5.312686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.383856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.534864</td>\n",
       "      <td>5.379193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.270781</td>\n",
       "      <td>21.932907</td>\n",
       "      <td>5.294547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.708151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.359639</td>\n",
       "      <td>5.363744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.061123</td>\n",
       "      <td>54.098064</td>\n",
       "      <td>5.307471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.501514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.367399</td>\n",
       "      <td>5.353343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.821146</td>\n",
       "      <td>27.337648</td>\n",
       "      <td>5.243687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.914024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.069599</td>\n",
       "      <td>5.343357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.738012</td>\n",
       "      <td>23.599577</td>\n",
       "      <td>5.225526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.451754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.026381</td>\n",
       "      <td>5.335067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.392506</td>\n",
       "      <td>50.074806</td>\n",
       "      <td>5.237674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.326107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.007844</td>\n",
       "      <td>5.334376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.755159</td>\n",
       "      <td>28.320770</td>\n",
       "      <td>5.225310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.035065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.898037</td>\n",
       "      <td>5.327632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.671903</td>\n",
       "      <td>24.601463</td>\n",
       "      <td>5.217128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.118280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.800867</td>\n",
       "      <td>5.324246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.725906</td>\n",
       "      <td>22.574551</td>\n",
       "      <td>5.212524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.443064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.139398</td>\n",
       "      <td>5.322168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.905081</td>\n",
       "      <td>22.110575</td>\n",
       "      <td>5.210916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.547079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.741854</td>\n",
       "      <td>5.320004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.559136</td>\n",
       "      <td>25.170074</td>\n",
       "      <td>5.204973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.260563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.980812</td>\n",
       "      <td>5.318426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.614425</td>\n",
       "      <td>22.034052</td>\n",
       "      <td>5.200174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.966982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.047421</td>\n",
       "      <td>5.317153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.761115</td>\n",
       "      <td>53.844444</td>\n",
       "      <td>5.209185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.522194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.070641</td>\n",
       "      <td>5.315036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.547786</td>\n",
       "      <td>17.281027</td>\n",
       "      <td>5.203202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.701370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.952858</td>\n",
       "      <td>5.311316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.763853</td>\n",
       "      <td>14.616241</td>\n",
       "      <td>5.192737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.572357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.788897</td>\n",
       "      <td>5.310793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.548711</td>\n",
       "      <td>27.747971</td>\n",
       "      <td>5.194070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.963488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.974073</td>\n",
       "      <td>5.309370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.664903</td>\n",
       "      <td>18.958864</td>\n",
       "      <td>5.193742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.755944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.772488</td>\n",
       "      <td>5.309232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.742481</td>\n",
       "      <td>18.521770</td>\n",
       "      <td>5.190050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.062240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.095572</td>\n",
       "      <td>5.307255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.454253</td>\n",
       "      <td>16.401926</td>\n",
       "      <td>5.192256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.294445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.958784</td>\n",
       "      <td>5.308939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.741601</td>\n",
       "      <td>15.067855</td>\n",
       "      <td>5.197520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.872285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.747117</td>\n",
       "      <td>5.304362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.820154</td>\n",
       "      <td>12.514209</td>\n",
       "      <td>5.192074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.247503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.578356</td>\n",
       "      <td>5.304705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.286363</td>\n",
       "      <td>16.282471</td>\n",
       "      <td>5.191700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.552113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.734003</td>\n",
       "      <td>5.303843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.554952</td>\n",
       "      <td>18.166258</td>\n",
       "      <td>5.186894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.042586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss      recon   kl        mmd    val_loss  val_recon  val_kl  \\\n",
       "0   53.256985  33.495697  0.0  20.150007   55.295570  10.631577     0.0   \n",
       "1   23.473732  10.354336  0.0  12.983544   50.409554  10.152746     0.0   \n",
       "2   17.250278   7.750245  0.0   9.421741  114.022728  14.419161     0.0   \n",
       "3   13.613574   6.423739  0.0   7.124564   65.223373   6.979677     0.0   \n",
       "4   11.657954   5.839181  0.0   5.965222   93.686180   6.759391     0.0   \n",
       "5   10.168350   5.576635  0.0   4.696644   42.958366   5.722135     0.0   \n",
       "6    9.831089   5.465136  0.0   4.591119   17.252010   5.386589     0.0   \n",
       "7    9.650624   5.411336  0.0   4.306530   30.674387   5.312686     0.0   \n",
       "8    9.534864   5.379193  0.0   4.270781   21.932907   5.294547     0.0   \n",
       "9    9.359639   5.363744  0.0   4.061123   54.098064   5.307471     0.0   \n",
       "10   9.367399   5.353343  0.0   3.821146   27.337648   5.243687     0.0   \n",
       "11   9.069599   5.343357  0.0   3.738012   23.599577   5.225526     0.0   \n",
       "12   9.026381   5.335067  0.0   3.392506   50.074806   5.237674     0.0   \n",
       "13   9.007844   5.334376  0.0   3.755159   28.320770   5.225310     0.0   \n",
       "14   8.898037   5.327632  0.0   3.671903   24.601463   5.217128     0.0   \n",
       "15   8.800867   5.324246  0.0   3.725906   22.574551   5.212524     0.0   \n",
       "16   9.139398   5.322168  0.0   3.905081   22.110575   5.210916     0.0   \n",
       "17   8.741854   5.320004  0.0   3.559136   25.170074   5.204973     0.0   \n",
       "18   8.980812   5.318426  0.0   3.614425   22.034052   5.200174     0.0   \n",
       "19   9.047421   5.317153  0.0   3.761115   53.844444   5.209185     0.0   \n",
       "20   9.070641   5.315036  0.0   3.547786   17.281027   5.203202     0.0   \n",
       "21   8.952858   5.311316  0.0   3.763853   14.616241   5.192737     0.0   \n",
       "22   8.788897   5.310793  0.0   3.548711   27.747971   5.194070     0.0   \n",
       "23   8.974073   5.309370  0.0   3.664903   18.958864   5.193742     0.0   \n",
       "24   8.772488   5.309232  0.0   3.742481   18.521770   5.190050     0.0   \n",
       "25   9.095572   5.307255  0.0   3.454253   16.401926   5.192256     0.0   \n",
       "26   8.958784   5.308939  0.0   3.741601   15.067855   5.197520     0.0   \n",
       "27   8.747117   5.304362  0.0   3.820154   12.514209   5.192074     0.0   \n",
       "28   8.578356   5.304705  0.0   3.286363   16.282471   5.191700     0.0   \n",
       "29   8.734003   5.303843  0.0   3.554952   18.166258   5.186894     0.0   \n",
       "\n",
       "      val_mmd  \n",
       "0   42.863033  \n",
       "1   44.747761  \n",
       "2   97.523895  \n",
       "3   58.460938  \n",
       "4   86.974808  \n",
       "5   34.796650  \n",
       "6   13.400815  \n",
       "7   26.383856  \n",
       "8   17.708151  \n",
       "9   53.501514  \n",
       "10  20.914024  \n",
       "11  17.451754  \n",
       "12  40.326107  \n",
       "13  22.035065  \n",
       "14  17.118280  \n",
       "15  18.443064  \n",
       "16  18.547079  \n",
       "17  21.260563  \n",
       "18  16.966982  \n",
       "19  49.522194  \n",
       "20  12.701370  \n",
       "21  10.572357  \n",
       "22  23.963488  \n",
       "23  14.755944  \n",
       "24  13.062240  \n",
       "25  12.294445  \n",
       "26   9.872285  \n",
       "27   7.247503  \n",
       "28  13.552113  \n",
       "29  12.042586  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save training performance\n",
    "history_df = pd.DataFrame(cp_vae.vae.history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e71d0f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/level5EncoderShuffled_mmd/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/level5DecoderShuffled_mmd/assets\n"
     ]
    }
   ],
   "source": [
    "encoder = cp_vae.encoder_block[\"encoder\"]\n",
    "decoder = cp_vae.decoder_block[\"decoder\"]\n",
    "encoder.save(\"models/level5EncoderShuffled_mmd\")\n",
    "decoder.save(\"models/level5DecoderShuffled_mmd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c23b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_df.to_csv('level5_training_mmd_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_training_data  = pd.read_csv('level5_training_mmd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3608be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7, 5), dpi = 400)\n",
    "# plt.plot(original_training_data[\"loss\"], label=\"Training data\")\n",
    "# plt.plot(original_training_data[\"val_loss\"], label=\"Validation data\")\n",
    "# plt.plot(history_df[\"loss\"], label=\"Shuffled training data\")\n",
    "# plt.plot(history_df[\"val_loss\"], label=\"Shuffled validation data\")\n",
    "# # plt.title(\"Loss for VAE training on Cell Painting Level 5 data\")\n",
    "# plt.ylabel(\"MSE + MMD\")\n",
    "# plt.xlabel(\"No. Epoch\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864dc53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
