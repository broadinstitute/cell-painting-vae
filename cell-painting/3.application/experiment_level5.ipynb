{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "/home/ubuntu/miniconda3/envs/cell-painting-vae/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycytominer.cyto_utils import infer_cp_features\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, \"../../scripts\")\n",
    "from utils import load_data\n",
    "from tensorflow import keras\n",
    "from scipy.stats import pearsonr, ttest_ind, ttest_1samp\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(82)\n",
    "NUM_RANDOM_SAMPLES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = load_data([\"complete\"])\n",
    "meta_features = infer_cp_features(data_dict[\"complete\"], metadata=True)\n",
    "cp_features = infer_cp_features(data_dict[\"complete\"])\n",
    "\n",
    "complete_features_df = data_dict[\"complete\"].reindex(cp_features, axis=\"columns\")\n",
    "complete_meta_df = data_dict[\"complete\"].reindex(meta_features, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "moas_occurrence = pd.read_csv(\"moas_occurrence.tsv\", sep = \"\\t\")\n",
    "moas_occurrence.index = moas_occurrence['moa']\n",
    "moas_occurrence = moas_occurrence.drop('moa', axis = 1)\n",
    "\n",
    "valid_pipes = moas_occurrence[((moas_occurrence != 0).all(axis = 1)) & (moas_occurrence['full moa occurrence'] > 0) & (moas_occurrence['moa1 occurrence'] > 0)& (moas_occurrence['moa2 occurrence'] > 0)].index\n",
    "valid_pipes = valid_pipes[valid_pipes.str.count(\"\\|\") == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(valid_pipes).to_csv('moas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_df(latent_df):\n",
    "    moa_df = pd.read_csv(\"repurposing_info_external_moa_map_resolved.tsv\",sep='\\t').set_index('broad_sample').reindex(index=complete_meta_df['Metadata_broad_sample']).reset_index().drop('Metadata_broad_sample',axis = 1)\n",
    "    moa_df.to_csv('moa_metadata.csv')\n",
    "    meta_moa_latent_df = pd.concat([complete_meta_df,moa_df,latent_df], axis=1)\n",
    "\n",
    "    # fill negative control DMSO profiles, change the NaN MOA label to be DMSO\n",
    "    meta_moa_latent_df.loc[meta_moa_latent_df['Metadata_broad_sample'] == 'DMSO', 'moa'] = 'DMSO'\n",
    "\n",
    "    #drop profiles with NaN MOAs\n",
    "    meta_moa_latent_df = meta_moa_latent_df.dropna(subset=['moa']).reset_index(drop = True)\n",
    "\n",
    "    # add columns to the dataframe that are randomnly shuffled permutations of the MOA column\n",
    "    for i in range(NUM_RANDOM_SAMPLES):\n",
    "        random_moa_labels = meta_moa_latent_df[['moa']].sample(frac=1).reset_index(drop=True)    \n",
    "        random_moa_labels = random_moa_labels.rename(columns={'moa': 'random_moa_labels' + str(i)})\n",
    "        meta_moa_latent_df = pd.concat([random_moa_labels, meta_moa_latent_df], axis=1)\n",
    "        \n",
    "    return meta_moa_latent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_by_moa(pipe, df_name, column):\n",
    "    moas = pipe.split(\"|\")\n",
    "    subset_df = pd.concat([df_name[df_name[column] == moas[0]],df_name[df_name[column] == moas[1]]])\n",
    "    return subset_df\n",
    "\n",
    "def LSA(A, B, D):\n",
    "    return A-D+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_means(meta_moa_latent_df, columns):\n",
    "    subset_means = []\n",
    "    subset_random_means = []\n",
    "\n",
    "    for pipe in valid_pipes:\n",
    "        subset = subset_by_moa(pipe, meta_moa_latent_df, 'moa')\n",
    "        subset_mean = subset.groupby(['moa'])[columns].mean()\n",
    "\n",
    "        subsets_random_mean = []\n",
    "        for i in range(NUM_RANDOM_SAMPLES):\n",
    "            moa_label = 'random_moa_labels' + str(i)\n",
    "            subset_random = subset_by_moa(pipe, meta_moa_latent_df, moa_label)\n",
    "            subset_random_mean = subset_random.groupby([moa_label])[columns].mean()\n",
    "            subsets_random_mean.append(subset_random_mean)\n",
    "\n",
    "        subset_means.append(subset_mean)\n",
    "\n",
    "        subset_random_means.append(subsets_random_mean)\n",
    "    \n",
    "    return subset_means, subset_random_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dmso_means(meta_moa_latent_df, columns):\n",
    "    DMSO = meta_moa_latent_df[meta_moa_latent_df.moa == 'DMSO']\n",
    "    DMSO_means = np.mean(DMSO[columns])\n",
    "\n",
    "    DMSO_means_random = []\n",
    "\n",
    "    for i in range(NUM_RANDOM_SAMPLES):\n",
    "        label = 'random_moa_labels' + str(i)\n",
    "        DMSO_random = meta_moa_latent_df[meta_moa_latent_df[label] == 'DMSO']\n",
    "        DMSO_means_random.append(np.mean(DMSO_random[columns]))\n",
    "    return DMSO_means, DMSO_means_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_post_LSA_representations(subset_means, subset_random_means, DMSO_means, DMSO_means_random):\n",
    "    representations_after_LSA = []\n",
    "    representations_after_LSA_random = []\n",
    "\n",
    "    for i in range(len(subset_means)):\n",
    "        \n",
    "        representation_after_LSA = LSA(subset_means[i].loc[valid_pipes[i].split(\"|\")[0]],subset_means[i].loc[valid_pipes[i].split(\"|\")[1]],DMSO_means)\n",
    "        representation_after_LSA = pd.DataFrame(representation_after_LSA).transpose()\n",
    "        representations_after_LSA.append(representation_after_LSA)\n",
    "\n",
    "        LSA_random_1pipe = []\n",
    "        for j in range(NUM_RANDOM_SAMPLES):\n",
    "            representation_after_LSA_random = LSA(subset_random_means[i][j].loc[valid_pipes[i].split(\"|\")[0]],subset_random_means[i][j].loc[valid_pipes[i].split(\"|\")[1]],DMSO_means_random[j])\n",
    "            representation_after_LSA_random = pd.DataFrame(representation_after_LSA_random).transpose()\n",
    "            LSA_random_1pipe.append(representation_after_LSA_random)    \n",
    "\n",
    "        representations_after_LSA_random.append(LSA_random_1pipe)\n",
    "\n",
    "    \n",
    "    return representations_after_LSA, representations_after_LSA_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_LSA_representations(representations_after_LSA, representations_after_LSA_random, model, decoder):\n",
    "    predictions = []\n",
    "    predictions_random = []\n",
    "    \n",
    "    for i in range(len(representations_after_LSA)):\n",
    "\n",
    "        if model not in ['pca', 'complete']:\n",
    "            prediction = decoder.predict(representations_after_LSA[i])\n",
    "        elif model == 'pca':\n",
    "            prediction = pca.inverse_transform(representations_after_LSA[i])\n",
    "        elif model == 'complete':    \n",
    "            prediction = representations_after_LSA[i].values.tolist()\n",
    "        else:\n",
    "            print('\"model\" must be \"vae\", \"pca\", or \"complete\"')\n",
    "            \n",
    "        predictions.append(pd.DataFrame(prediction))\n",
    "\n",
    "        predictions_random_1pipe = []\n",
    "\n",
    "        for j in range(NUM_RANDOM_SAMPLES):\n",
    "            if model not in ['pca', 'complete']:\n",
    "                prediction_random = decoder.predict(representations_after_LSA_random[i][j])\n",
    "            elif model == 'pca':\n",
    "                prediction_random = pca.inverse_transform(representations_after_LSA_random[i][j])\n",
    "            elif model == 'complete':\n",
    "                prediction_random = representations_after_LSA_random[i][j].values.tolist()\n",
    "            else:\n",
    "                print('\"model\" must be \"vae\", \"pca\", or \"complete\"')\n",
    "\n",
    "            predictions_random_1pipe.append(prediction_random)\n",
    "\n",
    "\n",
    "        predictions_random.append(predictions_random_1pipe)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    predictions_random = np.array(predictions_random)\n",
    "    \n",
    "    return predictions, predictions_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates all L2 distances for both per MOA combo and general distribution comparison for all MOA combos\n",
    "meta_moa_complete_df = generate_latent_df(complete_features_df)\n",
    "def calculate_L2_distances(predictions, predictions_random):\n",
    "    mean_of_moas = meta_moa_complete_df.groupby(['moa']).mean().loc[:,'Cells_AreaShape_FormFactor':]\n",
    "    L2 = []\n",
    "    L2_random = []\n",
    "    moa_similarity = []\n",
    "    per_moa_zscore = []\n",
    "    \n",
    "    mean = complete_features_df.mean()\n",
    "    for i in range(len(predictions)):\n",
    "        desired_moa = np.array(mean_of_moas[(mean_of_moas.index == valid_pipes[i])])\n",
    "        moa_similarity.append(np.linalg.norm(desired_moa[0] - mean))\n",
    "        #if L2_distance\n",
    "        L2_distance = np.linalg.norm(predictions[i]-desired_moa[0])\n",
    "        #if pearson\n",
    "#         L2_distance = scipy.stats.pearsonr(predictions[i][0], desired_moa[0])[0]\n",
    "        L2.append(L2_distance)\n",
    "        \n",
    "        L2_random_per_moa = []\n",
    "        for j in range(NUM_RANDOM_SAMPLES):\n",
    "            L2_distance_random = np.linalg.norm(predictions_random[i][j][0]-desired_moa[0])\n",
    "#             L2_distance_random = scipy.stats.pearsonr(predictions_random[i][j][0], desired_moa[0])[0]\n",
    "\n",
    "            L2_random_per_moa.append(L2_distance_random)\n",
    "\n",
    "        L2_random += L2_random_per_moa\n",
    "\n",
    "        zscore = scipy.stats.zscore(L2_random_per_moa + [L2_distance])[-1]\n",
    "        per_moa_zscore.append(zscore)\n",
    "\n",
    "    return L2, L2_random, moa_similarity, per_moa_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 10\n",
    "latent_space_columns = np.arange(0,latent_dim)\n",
    "latent_space_columns = [str(latent_space_column) for latent_space_column in latent_space_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_names = [\"beta\",\"vanilla\",\"mmd\",\"beta_leaveOut\",\"vanilla_leaveOut\",\"mmd_leaveOut\",\"pca\",\"complete\"]\n",
    "latent_names = [\"beta_leaveIntermediateOut\",\"vanilla_leaveIntermediateOut\",\"mmd_leaveIntermediateOut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dfs = {}\n",
    "for latent_name in latent_names:\n",
    "    if latent_name == \"pca\":\n",
    "        pca = PCA(n_components=latent_dim)\n",
    "        latent_dfs[latent_name] = pd.DataFrame(pca.fit_transform(complete_features_df), columns = latent_space_columns)\n",
    "    elif latent_name == \"complete\":\n",
    "        latent_dfs[latent_name] = complete_features_df\n",
    "    else:\n",
    "        latent_dfs[latent_name] = pd.read_csv(f\"level5Latent_{latent_name}.csv\").drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 22:06:21.479280: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-23 22:06:21.479324: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-23 22:06:21.479353: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-3-81): /proc/driver/nvidia/version does not exist\n",
      "2021-12-23 22:06:21.482064: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 22:06:21.936830: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "for latent_name in latent_dfs:\n",
    "    if latent_name == 'complete':\n",
    "        columns = complete_features_df.columns\n",
    "    else:\n",
    "        columns = latent_space_columns\n",
    "    meta_moa_latent_df = generate_latent_df(latent_dfs[latent_name])\n",
    "    subset_means, subset_random_means = calculate_means(meta_moa_latent_df, columns)\n",
    "    DMSO_means, DMSO_means_random  = calculate_dmso_means(meta_moa_latent_df, columns)\n",
    "    representations_after_LSA, representations_after_LSA_random = generate_post_LSA_representations(subset_means, subset_random_means, DMSO_means, DMSO_means_random)\n",
    "    decoder = None\n",
    "    if latent_name not in ['pca', 'complete']:\n",
    "        decoder = keras.models.load_model(f\"../2.train/models/level5Decoder_{latent_name}\")        \n",
    "    predictions, predictions_random = decode_LSA_representations(representations_after_LSA, representations_after_LSA_random, latent_name, decoder)\n",
    "    L2, L2_random, moa_similarity, per_moa_zscore = calculate_L2_distances(predictions, predictions_random)\n",
    "    per_moa_performance_df = pd.DataFrame({\"MOA\":valid_pipes,\"zscore\":per_moa_zscore,\"moa similarity\":moa_similarity})\n",
    "    per_moa_performance_df = per_moa_performance_df.sort_values('zscore')\n",
    "    per_moa_performance_df.to_csv(f'per_moa_performance/level5_{latent_name}_moa_performance.csv')\n",
    "    L2_df = pd.DataFrame(L2, columns = ['Unshuffled'])\n",
    "    L2_random_df = pd.DataFrame(L2_random, columns = ['Shuffled'])\n",
    "    L2_df = pd.concat([L2_df, L2_random_df], ignore_index = True, axis = 1)\n",
    "    L2_df.columns = ['Unshuffled','Shuffled']\n",
    "    L2_df.to_csv(f'L2_distances/level5_L2_general_{latent_name}.tsv', sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
